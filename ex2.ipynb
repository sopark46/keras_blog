{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 325us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 335us/step - loss: 1.7970 - acc: 0.2414 - val_loss: 1.8565 - val_acc: 0.1700\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 312us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8529 - val_acc: 0.1933\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 265us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8552 - val_acc: 0.1833\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 358us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8544 - val_acc: 0.1867\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 343us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 407us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 350us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 237us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 238us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 275us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8431 - val_acc: 0.2200\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.7641 - acc: 0.2729 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 154us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8215 - val_acc: 0.2167\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.7298 - acc: 0.2814 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.7255 - acc: 0.2871 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.7198 - acc: 0.2829 - val_loss: 1.8204 - val_acc: 0.2433\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 251us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 258us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8221 - val_acc: 0.2167\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8137 - val_acc: 0.2633\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8192 - val_acc: 0.2733\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 261us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 296us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8216 - val_acc: 0.2067\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.6969 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8179 - val_acc: 0.2300\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8148 - val_acc: 0.2133\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8129 - val_acc: 0.2333\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6661 - acc: 0.3114 - val_loss: 1.8220 - val_acc: 0.2200\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8140 - val_acc: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6606 - acc: 0.3243 - val_loss: 1.8213 - val_acc: 0.2333\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2500\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8227 - val_acc: 0.2733\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6466 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8285 - val_acc: 0.2267\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8198 - val_acc: 0.2200\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8337 - val_acc: 0.2433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8351 - val_acc: 0.2267\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8397 - val_acc: 0.2367\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.6151 - acc: 0.320 - 0s 144us/step - loss: 1.6230 - acc: 0.3286 - val_loss: 1.8344 - val_acc: 0.2233\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.6208 - acc: 0.3386 - val_loss: 1.8444 - val_acc: 0.2200\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6198 - acc: 0.3386 - val_loss: 1.8525 - val_acc: 0.2233\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6164 - acc: 0.3386 - val_loss: 1.8397 - val_acc: 0.2133\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8392 - val_acc: 0.2367\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6167 - acc: 0.3300 - val_loss: 1.8420 - val_acc: 0.2200\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6166 - acc: 0.3357 - val_loss: 1.8406 - val_acc: 0.2200\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.5950 - acc: 0.325 - 0s 145us/step - loss: 1.6143 - acc: 0.3229 - val_loss: 1.8437 - val_acc: 0.2600\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.6134 - acc: 0.3386 - val_loss: 1.8385 - val_acc: 0.2167\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6139 - acc: 0.3371 - val_loss: 1.8446 - val_acc: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6134 - acc: 0.3386 - val_loss: 1.8376 - val_acc: 0.2233\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6111 - acc: 0.3371 - val_loss: 1.8415 - val_acc: 0.2667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8339 - val_acc: 0.2567\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8365 - val_acc: 0.2167\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6115 - acc: 0.3286 - val_loss: 1.8411 - val_acc: 0.2333\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6093 - acc: 0.3443 - val_loss: 1.8453 - val_acc: 0.2267\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6076 - acc: 0.3371 - val_loss: 1.8641 - val_acc: 0.2200\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8449 - val_acc: 0.2233\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6065 - acc: 0.3543 - val_loss: 1.8443 - val_acc: 0.2167\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8412 - val_acc: 0.2133\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8517 - val_acc: 0.2233\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8402 - val_acc: 0.2300\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8564 - val_acc: 0.2233\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6044 - acc: 0.3500 - val_loss: 1.8503 - val_acc: 0.2200\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6029 - acc: 0.3371 - val_loss: 1.8539 - val_acc: 0.2267\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8471 - val_acc: 0.2267\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8453 - val_acc: 0.2467\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8472 - val_acc: 0.2167\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8489 - val_acc: 0.2300\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8592 - val_acc: 0.2200\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6003 - acc: 0.3429 - val_loss: 1.8558 - val_acc: 0.2200\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8604 - val_acc: 0.2633\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5986 - acc: 0.3457 - val_loss: 1.8469 - val_acc: 0.2167\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5979 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2100\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5965 - acc: 0.3343 - val_loss: 1.8562 - val_acc: 0.2267\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8462 - val_acc: 0.2067\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8508 - val_acc: 0.2200\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5946 - acc: 0.3500 - val_loss: 1.8463 - val_acc: 0.2133\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8537 - val_acc: 0.2233\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8557 - val_acc: 0.2233\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5919 - acc: 0.3514 - val_loss: 1.8521 - val_acc: 0.2300\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.5915 - acc: 0.3443 - val_loss: 1.8523 - val_acc: 0.2267\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5904 - acc: 0.3371 - val_loss: 1.8456 - val_acc: 0.2567\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8593 - val_acc: 0.2200\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8520 - val_acc: 0.2233\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5905 - acc: 0.3443 - val_loss: 1.8541 - val_acc: 0.2267\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.5896 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.5882 - acc: 0.3471 - val_loss: 1.8638 - val_acc: 0.2300\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.5876 - acc: 0.3486 - val_loss: 1.8600 - val_acc: 0.2300\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5865 - acc: 0.3500 - val_loss: 1.8659 - val_acc: 0.2267\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8582 - val_acc: 0.2267\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5856 - acc: 0.3471 - val_loss: 1.8621 - val_acc: 0.2267\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8751 - val_acc: 0.2500\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8615 - val_acc: 0.2600\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5845 - acc: 0.3529 - val_loss: 1.8766 - val_acc: 0.2467\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8572 - val_acc: 0.2167\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5835 - acc: 0.3486 - val_loss: 1.8686 - val_acc: 0.2233\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5825 - acc: 0.3500 - val_loss: 1.8612 - val_acc: 0.2133\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5825 - acc: 0.3443 - val_loss: 1.8693 - val_acc: 0.2267\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5801 - acc: 0.3486 - val_loss: 1.8688 - val_acc: 0.2233\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8635 - val_acc: 0.2133\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8606 - val_acc: 0.2233\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.5810 - acc: 0.3514 - val_loss: 1.8731 - val_acc: 0.2133\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.5797 - acc: 0.3486 - val_loss: 1.8781 - val_acc: 0.2200\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.5777 - acc: 0.3557 - val_loss: 1.8693 - val_acc: 0.2100\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.5779 - acc: 0.3443 - val_loss: 1.8665 - val_acc: 0.2133\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8718 - val_acc: 0.2300\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 150us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8613 - val_acc: 0.2200\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8682 - val_acc: 0.2267\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5750 - acc: 0.3571 - val_loss: 1.8721 - val_acc: 0.2500\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8738 - val_acc: 0.2433\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8734 - val_acc: 0.2100\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8806 - val_acc: 0.2200\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5713 - acc: 0.3557 - val_loss: 1.8724 - val_acc: 0.2200\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8839 - val_acc: 0.2233\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5712 - acc: 0.3543 - val_loss: 1.8710 - val_acc: 0.2533\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5722 - acc: 0.3557 - val_loss: 1.8631 - val_acc: 0.2167\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.5636 - acc: 0.352 - 0s 133us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8700 - val_acc: 0.2233\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5712 - acc: 0.3457 - val_loss: 1.8840 - val_acc: 0.2233\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.5814 - acc: 0.358 - 0s 125us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8981 - val_acc: 0.2167\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.5705 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5689 - acc: 0.3586 - val_loss: 1.8820 - val_acc: 0.2133\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5677 - acc: 0.3586 - val_loss: 1.8836 - val_acc: 0.2267\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8913 - val_acc: 0.2467\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5650 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8912 - val_acc: 0.2167\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8989 - val_acc: 0.2200\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5638 - acc: 0.3571 - val_loss: 1.8751 - val_acc: 0.2167\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5638 - acc: 0.3614 - val_loss: 1.8836 - val_acc: 0.2100\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5631 - acc: 0.3629 - val_loss: 1.8859 - val_acc: 0.2100\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5640 - acc: 0.3571 - val_loss: 1.8813 - val_acc: 0.2133\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8902 - val_acc: 0.2200\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8968 - val_acc: 0.2500\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5613 - acc: 0.3629 - val_loss: 1.8919 - val_acc: 0.2300\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5613 - acc: 0.3614 - val_loss: 1.8757 - val_acc: 0.2100\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5601 - acc: 0.3643 - val_loss: 1.8854 - val_acc: 0.2133\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5594 - acc: 0.3671 - val_loss: 1.8674 - val_acc: 0.2333\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8914 - val_acc: 0.2333\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.5595 - acc: 0.3600 - val_loss: 1.9030 - val_acc: 0.2267\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8965 - val_acc: 0.2200\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5589 - acc: 0.3457 - val_loss: 1.8841 - val_acc: 0.2233\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5589 - acc: 0.3614 - val_loss: 1.8914 - val_acc: 0.2200\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8968 - val_acc: 0.2533\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 1.5581 - acc: 0.3714 - val_loss: 1.8910 - val_acc: 0.2167\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5578 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5541 - acc: 0.3571 - val_loss: 1.8906 - val_acc: 0.2333\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8927 - val_acc: 0.2167\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8936 - val_acc: 0.2567\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5535 - acc: 0.3557 - val_loss: 1.8887 - val_acc: 0.2200\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8989 - val_acc: 0.2233\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5527 - acc: 0.3686 - val_loss: 1.9019 - val_acc: 0.2133\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8930 - val_acc: 0.2133\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5519 - acc: 0.3600 - val_loss: 1.9014 - val_acc: 0.2167\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9032 - val_acc: 0.2200\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5514 - acc: 0.3586 - val_loss: 1.9037 - val_acc: 0.2167\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2433\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9012 - val_acc: 0.2300\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5498 - acc: 0.3543 - val_loss: 1.9003 - val_acc: 0.2567\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9120 - val_acc: 0.2200\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9104 - val_acc: 0.2133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9128 - val_acc: 0.2167\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9145 - val_acc: 0.2267\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5470 - acc: 0.3629 - val_loss: 1.8934 - val_acc: 0.2200\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9081 - val_acc: 0.2167\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5465 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 1.5453 - acc: 0.3671 - val_loss: 1.9067 - val_acc: 0.2200\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5431 - acc: 0.3643 - val_loss: 1.9152 - val_acc: 0.2267\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5458 - acc: 0.3614 - val_loss: 1.9108 - val_acc: 0.2267\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5436 - acc: 0.3657 - val_loss: 1.9070 - val_acc: 0.2267\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5453 - acc: 0.3600 - val_loss: 1.9136 - val_acc: 0.2333\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5436 - acc: 0.3643 - val_loss: 1.9128 - val_acc: 0.2367\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5448 - acc: 0.3657 - val_loss: 1.9116 - val_acc: 0.2167\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5426 - acc: 0.3571 - val_loss: 1.9064 - val_acc: 0.2300\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5423 - acc: 0.3714 - val_loss: 1.9278 - val_acc: 0.2367\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5387 - acc: 0.3671 - val_loss: 1.9050 - val_acc: 0.2633\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5432 - acc: 0.3714 - val_loss: 1.9103 - val_acc: 0.2300\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5407 - acc: 0.3657 - val_loss: 1.9128 - val_acc: 0.2233\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5405 - acc: 0.3600 - val_loss: 1.9141 - val_acc: 0.2267\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5412 - acc: 0.3614 - val_loss: 1.9217 - val_acc: 0.2300\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9104 - val_acc: 0.2300\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5390 - acc: 0.3600 - val_loss: 1.9099 - val_acc: 0.2300\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9285 - val_acc: 0.2267\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5393 - acc: 0.3686 - val_loss: 1.9264 - val_acc: 0.2300\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9186 - val_acc: 0.2533\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9198 - val_acc: 0.2300\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5373 - acc: 0.3671 - val_loss: 1.9231 - val_acc: 0.2200\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5386 - acc: 0.3600 - val_loss: 1.9138 - val_acc: 0.2100\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5366 - acc: 0.3614 - val_loss: 1.9262 - val_acc: 0.2267\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5360 - acc: 0.3743 - val_loss: 1.9368 - val_acc: 0.2333\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5367 - acc: 0.3614 - val_loss: 1.9303 - val_acc: 0.2233\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5356 - acc: 0.3714 - val_loss: 1.9143 - val_acc: 0.2300\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5352 - acc: 0.3586 - val_loss: 1.9218 - val_acc: 0.2333\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5339 - acc: 0.3700 - val_loss: 1.9150 - val_acc: 0.2200\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5345 - acc: 0.3586 - val_loss: 1.9315 - val_acc: 0.2500\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5358 - acc: 0.3686 - val_loss: 1.9231 - val_acc: 0.2233\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9285 - val_acc: 0.2233\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.5327 - acc: 0.3771 - val_loss: 1.9241 - val_acc: 0.2567\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.5335 - acc: 0.3800 - val_loss: 1.9180 - val_acc: 0.2300\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5330 - acc: 0.3771 - val_loss: 1.9326 - val_acc: 0.2300\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5320 - acc: 0.3743 - val_loss: 1.9237 - val_acc: 0.2133\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5314 - acc: 0.3700 - val_loss: 1.9162 - val_acc: 0.2167\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.5328 - acc: 0.3729 - val_loss: 1.9402 - val_acc: 0.2300\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.5316 - acc: 0.3757 - val_loss: 1.9260 - val_acc: 0.2300\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5313 - acc: 0.3600 - val_loss: 1.9439 - val_acc: 0.2167\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5310 - acc: 0.3671 - val_loss: 1.9327 - val_acc: 0.2300\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9426 - val_acc: 0.2300\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9439 - val_acc: 0.2567\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5301 - acc: 0.3700 - val_loss: 1.9311 - val_acc: 0.2267\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5278 - acc: 0.3814 - val_loss: 1.9199 - val_acc: 0.2200\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5285 - acc: 0.3643 - val_loss: 1.9295 - val_acc: 0.2133\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5282 - acc: 0.3700 - val_loss: 1.9272 - val_acc: 0.2133\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5282 - acc: 0.3657 - val_loss: 1.9310 - val_acc: 0.2300\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5264 - acc: 0.3757 - val_loss: 1.9308 - val_acc: 0.2333\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9281 - val_acc: 0.2300\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.5256 - acc: 0.3657 - val_loss: 1.9422 - val_acc: 0.2333\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.5280 - acc: 0.3714 - val_loss: 1.9345 - val_acc: 0.2167\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5261 - acc: 0.3600 - val_loss: 1.9551 - val_acc: 0.2300\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 174us/step - loss: 1.5261 - acc: 0.3700 - val_loss: 1.9441 - val_acc: 0.2433\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5260 - acc: 0.3714 - val_loss: 1.9362 - val_acc: 0.2267\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5250 - acc: 0.3700 - val_loss: 1.9506 - val_acc: 0.2233\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5252 - acc: 0.3700 - val_loss: 1.9460 - val_acc: 0.2133\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5232 - acc: 0.3729 - val_loss: 1.9459 - val_acc: 0.2233\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5232 - acc: 0.3686 - val_loss: 1.9475 - val_acc: 0.2333\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5240 - acc: 0.3629 - val_loss: 1.9495 - val_acc: 0.2233\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5216 - acc: 0.3757 - val_loss: 1.9515 - val_acc: 0.2333\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5230 - acc: 0.3614 - val_loss: 1.9372 - val_acc: 0.2267\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5225 - acc: 0.3771 - val_loss: 1.9519 - val_acc: 0.2267\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 1.5223 - acc: 0.3714 - val_loss: 1.9401 - val_acc: 0.2133\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5222 - acc: 0.3757 - val_loss: 1.9564 - val_acc: 0.2300\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5207 - acc: 0.3786 - val_loss: 1.9551 - val_acc: 0.2367\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5208 - acc: 0.3614 - val_loss: 1.9319 - val_acc: 0.2367\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9531 - val_acc: 0.2400\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5210 - acc: 0.3671 - val_loss: 1.9506 - val_acc: 0.2233\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5195 - acc: 0.3729 - val_loss: 1.9587 - val_acc: 0.2333\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9450 - val_acc: 0.2133\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5196 - acc: 0.3671 - val_loss: 1.9517 - val_acc: 0.2267\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9385 - val_acc: 0.2267\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5182 - acc: 0.3786 - val_loss: 1.9487 - val_acc: 0.2167\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5170 - acc: 0.3743 - val_loss: 1.9761 - val_acc: 0.2267\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5184 - acc: 0.3743 - val_loss: 1.9742 - val_acc: 0.2333\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 1.5187 - acc: 0.3657 - val_loss: 1.9516 - val_acc: 0.2333\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5167 - acc: 0.3700 - val_loss: 1.9601 - val_acc: 0.2567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5178 - acc: 0.3786 - val_loss: 1.9714 - val_acc: 0.2167\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5162 - acc: 0.3714 - val_loss: 1.9588 - val_acc: 0.2233\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.5155 - acc: 0.3686 - val_loss: 1.9711 - val_acc: 0.2400\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9510 - val_acc: 0.2200\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5163 - acc: 0.3729 - val_loss: 1.9574 - val_acc: 0.2267\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5156 - acc: 0.3700 - val_loss: 1.9505 - val_acc: 0.2333\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5153 - acc: 0.3729 - val_loss: 1.9581 - val_acc: 0.2300\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5143 - acc: 0.3714 - val_loss: 1.9671 - val_acc: 0.2467\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.5179 - acc: 0.381 - 0s 134us/step - loss: 1.5159 - acc: 0.3786 - val_loss: 1.9493 - val_acc: 0.2267\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9574 - val_acc: 0.2400\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5132 - acc: 0.3743 - val_loss: 1.9542 - val_acc: 0.2367\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5138 - acc: 0.3714 - val_loss: 1.9601 - val_acc: 0.2233\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5137 - acc: 0.3743 - val_loss: 1.9732 - val_acc: 0.2233\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5136 - acc: 0.3757 - val_loss: 1.9567 - val_acc: 0.2267\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.5132 - acc: 0.3786 - val_loss: 1.9565 - val_acc: 0.2167\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5125 - acc: 0.3771 - val_loss: 1.9619 - val_acc: 0.2167\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.5110 - acc: 0.3857 - val_loss: 1.9756 - val_acc: 0.2333\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5124 - acc: 0.3643 - val_loss: 1.9590 - val_acc: 0.2200\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5107 - acc: 0.3757 - val_loss: 1.9873 - val_acc: 0.2333\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5113 - acc: 0.3643 - val_loss: 1.9600 - val_acc: 0.2167\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9595 - val_acc: 0.2267\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9651 - val_acc: 0.2233\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 1.5069 - acc: 0.3814 - val_loss: 1.9932 - val_acc: 0.2200\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.5086 - acc: 0.3743 - val_loss: 1.9660 - val_acc: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.5074 - acc: 0.3786 - val_loss: 1.9797 - val_acc: 0.2267\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5084 - acc: 0.3771 - val_loss: 1.9834 - val_acc: 0.2200\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5081 - acc: 0.3729 - val_loss: 1.9785 - val_acc: 0.2267\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5077 - acc: 0.3757 - val_loss: 1.9699 - val_acc: 0.2267\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5039 - acc: 0.3686 - val_loss: 1.9804 - val_acc: 0.2300\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5058 - acc: 0.3757 - val_loss: 1.9605 - val_acc: 0.2267\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5057 - acc: 0.3714 - val_loss: 1.9817 - val_acc: 0.2300\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5047 - acc: 0.3829 - val_loss: 1.9730 - val_acc: 0.2233\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5033 - acc: 0.3757 - val_loss: 1.9687 - val_acc: 0.2333\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5042 - acc: 0.3786 - val_loss: 1.9829 - val_acc: 0.2300\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 162us/step - loss: 1.5016 - acc: 0.3757 - val_loss: 1.9791 - val_acc: 0.2333\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9892 - val_acc: 0.2267\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5032 - acc: 0.3786 - val_loss: 1.9809 - val_acc: 0.2233\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5017 - acc: 0.3886 - val_loss: 1.9790 - val_acc: 0.2367\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5019 - acc: 0.3757 - val_loss: 1.9663 - val_acc: 0.2200\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5016 - acc: 0.3800 - val_loss: 1.9882 - val_acc: 0.2300\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.5011 - acc: 0.3814 - val_loss: 1.9666 - val_acc: 0.2400\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5005 - acc: 0.3743 - val_loss: 1.9744 - val_acc: 0.2433\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9790 - val_acc: 0.2367\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5002 - acc: 0.3757 - val_loss: 1.9680 - val_acc: 0.2200\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9620 - val_acc: 0.2400\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9792 - val_acc: 0.2167\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4983 - acc: 0.3829 - val_loss: 1.9834 - val_acc: 0.2533\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.4985 - acc: 0.3843 - val_loss: 2.0046 - val_acc: 0.2300\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9697 - val_acc: 0.2300\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4978 - acc: 0.3829 - val_loss: 1.9810 - val_acc: 0.2467\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4990 - acc: 0.3800 - val_loss: 1.9880 - val_acc: 0.2333\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9816 - val_acc: 0.2233\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4968 - acc: 0.3771 - val_loss: 1.9851 - val_acc: 0.2367\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4976 - acc: 0.3757 - val_loss: 1.9876 - val_acc: 0.2233\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4957 - acc: 0.3871 - val_loss: 1.9827 - val_acc: 0.2267\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9700 - val_acc: 0.2200\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4958 - acc: 0.3943 - val_loss: 1.9953 - val_acc: 0.2200\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4948 - acc: 0.3857 - val_loss: 1.9638 - val_acc: 0.2300\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4948 - acc: 0.3757 - val_loss: 1.9837 - val_acc: 0.2267\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4960 - acc: 0.3829 - val_loss: 1.9800 - val_acc: 0.2300\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4952 - acc: 0.3886 - val_loss: 1.9824 - val_acc: 0.2300\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4945 - acc: 0.3843 - val_loss: 1.9938 - val_acc: 0.2233\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4938 - acc: 0.3871 - val_loss: 1.9891 - val_acc: 0.2400\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4947 - acc: 0.3829 - val_loss: 1.9921 - val_acc: 0.2233\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4941 - acc: 0.3829 - val_loss: 1.9960 - val_acc: 0.2300\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4932 - acc: 0.3886 - val_loss: 2.0017 - val_acc: 0.2267\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4926 - acc: 0.3814 - val_loss: 2.0141 - val_acc: 0.2300\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4927 - acc: 0.3843 - val_loss: 1.9926 - val_acc: 0.2267\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4919 - acc: 0.3886 - val_loss: 2.0022 - val_acc: 0.2333\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4930 - acc: 0.3843 - val_loss: 1.9927 - val_acc: 0.2233\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4919 - acc: 0.3843 - val_loss: 1.9985 - val_acc: 0.2233\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4911 - acc: 0.3871 - val_loss: 1.9970 - val_acc: 0.2300\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4908 - acc: 0.3914 - val_loss: 1.9901 - val_acc: 0.2333\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4909 - acc: 0.3871 - val_loss: 1.9964 - val_acc: 0.2333\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4907 - acc: 0.3857 - val_loss: 1.9878 - val_acc: 0.2267\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9915 - val_acc: 0.2467\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4898 - acc: 0.3871 - val_loss: 1.9998 - val_acc: 0.2333\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4903 - acc: 0.3829 - val_loss: 1.9941 - val_acc: 0.2267\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4881 - acc: 0.3957 - val_loss: 1.9949 - val_acc: 0.2467\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.4900 - acc: 0.3900 - val_loss: 2.0007 - val_acc: 0.2300\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4884 - acc: 0.3971 - val_loss: 2.0000 - val_acc: 0.2300\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4883 - acc: 0.3900 - val_loss: 1.9928 - val_acc: 0.2267\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4873 - acc: 0.3886 - val_loss: 2.0004 - val_acc: 0.2467\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4872 - acc: 0.3871 - val_loss: 1.9884 - val_acc: 0.2333\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4877 - acc: 0.3886 - val_loss: 1.9969 - val_acc: 0.2233\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 1.4871 - acc: 0.3757 - val_loss: 2.0010 - val_acc: 0.2267\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.4873 - acc: 0.3871 - val_loss: 2.0061 - val_acc: 0.2267\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4866 - acc: 0.3843 - val_loss: 1.9970 - val_acc: 0.2267\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4860 - acc: 0.3871 - val_loss: 2.0308 - val_acc: 0.2333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4870 - acc: 0.3886 - val_loss: 2.0095 - val_acc: 0.2233\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4859 - acc: 0.3943 - val_loss: 2.0062 - val_acc: 0.2233\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4845 - acc: 0.3957 - val_loss: 2.0114 - val_acc: 0.2367\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4849 - acc: 0.3900 - val_loss: 2.0125 - val_acc: 0.2367\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 140us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9975 - val_acc: 0.2267\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4843 - acc: 0.3900 - val_loss: 2.0051 - val_acc: 0.2267\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4835 - acc: 0.3886 - val_loss: 2.0056 - val_acc: 0.2267\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4839 - acc: 0.3900 - val_loss: 2.0097 - val_acc: 0.2233\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4837 - acc: 0.3929 - val_loss: 2.0054 - val_acc: 0.2333\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4836 - acc: 0.3900 - val_loss: 2.0027 - val_acc: 0.2300\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4824 - acc: 0.3943 - val_loss: 2.0108 - val_acc: 0.2367\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4821 - acc: 0.3886 - val_loss: 2.0181 - val_acc: 0.2400\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4808 - acc: 0.4000 - val_loss: 2.0183 - val_acc: 0.2333\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4821 - acc: 0.4000 - val_loss: 2.0166 - val_acc: 0.2367\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4815 - acc: 0.3986 - val_loss: 2.0163 - val_acc: 0.2400\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4810 - acc: 0.4029 - val_loss: 2.0131 - val_acc: 0.2267\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4808 - acc: 0.3857 - val_loss: 2.0083 - val_acc: 0.2467\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4813 - acc: 0.3957 - val_loss: 2.0133 - val_acc: 0.2500\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4809 - acc: 0.3929 - val_loss: 2.0149 - val_acc: 0.2500\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4805 - acc: 0.3900 - val_loss: 2.0077 - val_acc: 0.2300\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0006 - val_acc: 0.2333\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.4806 - acc: 0.3886 - val_loss: 2.0218 - val_acc: 0.2300\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4799 - acc: 0.3914 - val_loss: 2.0014 - val_acc: 0.2267\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4797 - acc: 0.4000 - val_loss: 2.0053 - val_acc: 0.2333\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4803 - acc: 0.3914 - val_loss: 2.0076 - val_acc: 0.2233\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4793 - acc: 0.4029 - val_loss: 2.0259 - val_acc: 0.2333\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4786 - acc: 0.3857 - val_loss: 2.0115 - val_acc: 0.2400\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4774 - acc: 0.3886 - val_loss: 2.0167 - val_acc: 0.2467\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4764 - acc: 0.3886 - val_loss: 2.0477 - val_acc: 0.2367\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4777 - acc: 0.4029 - val_loss: 2.0263 - val_acc: 0.2367\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4781 - acc: 0.3929 - val_loss: 2.0257 - val_acc: 0.2367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4783 - acc: 0.3986 - val_loss: 2.0258 - val_acc: 0.2300\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4759 - acc: 0.3957 - val_loss: 2.0255 - val_acc: 0.2267\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4765 - acc: 0.3957 - val_loss: 2.0207 - val_acc: 0.2267\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4758 - acc: 0.3971 - val_loss: 2.0244 - val_acc: 0.2267\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4754 - acc: 0.3957 - val_loss: 2.0208 - val_acc: 0.2400\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4754 - acc: 0.3986 - val_loss: 2.0150 - val_acc: 0.2300\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4770 - acc: 0.3986 - val_loss: 2.0222 - val_acc: 0.2233\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4750 - acc: 0.3886 - val_loss: 2.0239 - val_acc: 0.2267\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4744 - acc: 0.3943 - val_loss: 2.0374 - val_acc: 0.2333\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0230 - val_acc: 0.2233\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4738 - acc: 0.4043 - val_loss: 2.0185 - val_acc: 0.2267\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4741 - acc: 0.3957 - val_loss: 2.0112 - val_acc: 0.2467\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4730 - acc: 0.3957 - val_loss: 2.0144 - val_acc: 0.2433\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4727 - acc: 0.3986 - val_loss: 2.0264 - val_acc: 0.2267\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4735 - acc: 0.4029 - val_loss: 2.0251 - val_acc: 0.2300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4741 - acc: 0.3957 - val_loss: 2.0271 - val_acc: 0.2267\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4705 - acc: 0.3929 - val_loss: 2.0358 - val_acc: 0.2500\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4740 - acc: 0.4029 - val_loss: 2.0343 - val_acc: 0.2267\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4727 - acc: 0.4029 - val_loss: 2.0244 - val_acc: 0.2300\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4718 - acc: 0.3957 - val_loss: 2.0314 - val_acc: 0.2400\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4714 - acc: 0.4143 - val_loss: 2.0129 - val_acc: 0.2367\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.4725 - acc: 0.3986 - val_loss: 2.0337 - val_acc: 0.2267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4721 - acc: 0.3943 - val_loss: 2.0291 - val_acc: 0.2267\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0225 - val_acc: 0.2333\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4696 - acc: 0.4014 - val_loss: 2.0283 - val_acc: 0.2467\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4710 - acc: 0.3971 - val_loss: 2.0254 - val_acc: 0.2267\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4702 - acc: 0.3943 - val_loss: 2.0254 - val_acc: 0.2300\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0288 - val_acc: 0.2267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4681 - acc: 0.3929 - val_loss: 2.0334 - val_acc: 0.2267\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.4686 - acc: 0.4014 - val_loss: 2.0410 - val_acc: 0.2267\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4688 - acc: 0.3957 - val_loss: 2.0247 - val_acc: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4691 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 142us/step - loss: 1.4684 - acc: 0.4000 - val_loss: 2.0309 - val_acc: 0.2300\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4689 - acc: 0.3971 - val_loss: 2.0268 - val_acc: 0.2300\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0506 - val_acc: 0.2433\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4671 - acc: 0.4057 - val_loss: 2.0457 - val_acc: 0.2267\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4676 - acc: 0.4043 - val_loss: 2.0286 - val_acc: 0.2300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4670 - acc: 0.3943 - val_loss: 2.0372 - val_acc: 0.2333\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0317 - val_acc: 0.2267\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4678 - acc: 0.4014 - val_loss: 2.0413 - val_acc: 0.2267\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4668 - acc: 0.4000 - val_loss: 2.0375 - val_acc: 0.2267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4666 - acc: 0.4043 - val_loss: 2.0427 - val_acc: 0.2433\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4671 - acc: 0.3986 - val_loss: 2.0334 - val_acc: 0.2333\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4657 - acc: 0.3929 - val_loss: 2.0252 - val_acc: 0.2367\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4665 - acc: 0.4014 - val_loss: 2.0335 - val_acc: 0.2300\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4636 - acc: 0.4000 - val_loss: 2.0474 - val_acc: 0.2533\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4659 - acc: 0.3957 - val_loss: 2.0508 - val_acc: 0.2367\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4643 - acc: 0.3971 - val_loss: 2.0293 - val_acc: 0.2300\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4647 - acc: 0.4057 - val_loss: 2.0286 - val_acc: 0.2333\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4641 - acc: 0.4000 - val_loss: 2.0417 - val_acc: 0.2300\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4647 - acc: 0.3971 - val_loss: 2.0368 - val_acc: 0.2300\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4630 - acc: 0.4086 - val_loss: 2.0369 - val_acc: 0.2333\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4655 - acc: 0.4014 - val_loss: 2.0347 - val_acc: 0.2300\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.4629 - acc: 0.4000 - val_loss: 2.0433 - val_acc: 0.2300\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4637 - acc: 0.4057 - val_loss: 2.0459 - val_acc: 0.2400\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4622 - acc: 0.4029 - val_loss: 2.0392 - val_acc: 0.2433\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4614 - acc: 0.4114 - val_loss: 2.0559 - val_acc: 0.2500\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4631 - acc: 0.4086 - val_loss: 2.0375 - val_acc: 0.2300\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4614 - acc: 0.4029 - val_loss: 2.0423 - val_acc: 0.2533\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4613 - acc: 0.3986 - val_loss: 2.0468 - val_acc: 0.2567\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4622 - acc: 0.4086 - val_loss: 2.0374 - val_acc: 0.2267\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4619 - acc: 0.4057 - val_loss: 2.0327 - val_acc: 0.2267\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4613 - acc: 0.4029 - val_loss: 2.0365 - val_acc: 0.2267\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4612 - acc: 0.4071 - val_loss: 2.0515 - val_acc: 0.2300\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4604 - acc: 0.4043 - val_loss: 2.0381 - val_acc: 0.2333\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4620 - acc: 0.4100 - val_loss: 2.0476 - val_acc: 0.2333\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4599 - acc: 0.4171 - val_loss: 2.0512 - val_acc: 0.2333\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 1.4599 - acc: 0.4057 - val_loss: 2.0491 - val_acc: 0.2433\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4593 - acc: 0.4057 - val_loss: 2.0439 - val_acc: 0.2533\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4587 - acc: 0.4114 - val_loss: 2.0512 - val_acc: 0.2333\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4588 - acc: 0.4043 - val_loss: 2.0485 - val_acc: 0.2300\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0402 - val_acc: 0.2333\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0554 - val_acc: 0.2533\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4598 - acc: 0.4043 - val_loss: 2.0418 - val_acc: 0.2500\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4597 - acc: 0.4114 - val_loss: 2.0479 - val_acc: 0.2300\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4586 - acc: 0.3971 - val_loss: 2.0453 - val_acc: 0.2300\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.4584 - acc: 0.3986 - val_loss: 2.0453 - val_acc: 0.2300\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4578 - acc: 0.4071 - val_loss: 2.0457 - val_acc: 0.2367\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4584 - acc: 0.4071 - val_loss: 2.0432 - val_acc: 0.2267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4575 - acc: 0.4100 - val_loss: 2.0537 - val_acc: 0.2367\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4571 - acc: 0.4071 - val_loss: 2.0491 - val_acc: 0.2567\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4569 - acc: 0.4071 - val_loss: 2.0519 - val_acc: 0.2267\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4563 - acc: 0.4029 - val_loss: 2.0510 - val_acc: 0.2267\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.4570 - acc: 0.4057 - val_loss: 2.0549 - val_acc: 0.2267\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4557 - acc: 0.4100 - val_loss: 2.0537 - val_acc: 0.2300\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4549 - acc: 0.4029 - val_loss: 2.0548 - val_acc: 0.2500\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4574 - acc: 0.4143 - val_loss: 2.0552 - val_acc: 0.2333\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4560 - acc: 0.4057 - val_loss: 2.0586 - val_acc: 0.2300\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4553 - acc: 0.4086 - val_loss: 2.0567 - val_acc: 0.2267\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4553 - acc: 0.4043 - val_loss: 2.0491 - val_acc: 0.2300\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4554 - acc: 0.4071 - val_loss: 2.0602 - val_acc: 0.2267\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 162us/step - loss: 1.4545 - acc: 0.4086 - val_loss: 2.0557 - val_acc: 0.2333\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4545 - acc: 0.4071 - val_loss: 2.0496 - val_acc: 0.2267\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4539 - acc: 0.4157 - val_loss: 2.0520 - val_acc: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4542 - acc: 0.4057 - val_loss: 2.0555 - val_acc: 0.2433\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4537 - acc: 0.4129 - val_loss: 2.0462 - val_acc: 0.2300\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4526 - acc: 0.4143 - val_loss: 2.0481 - val_acc: 0.2500\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4537 - acc: 0.3929 - val_loss: 2.0565 - val_acc: 0.2267\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4542 - acc: 0.4043 - val_loss: 2.0475 - val_acc: 0.2367\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4526 - acc: 0.4157 - val_loss: 2.0618 - val_acc: 0.2300\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4523 - acc: 0.4129 - val_loss: 2.0603 - val_acc: 0.2433\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4526 - acc: 0.4043 - val_loss: 2.0581 - val_acc: 0.2367\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4527 - acc: 0.4114 - val_loss: 2.0486 - val_acc: 0.2400\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4526 - acc: 0.4014 - val_loss: 2.0487 - val_acc: 0.2400\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4516 - acc: 0.4057 - val_loss: 2.0550 - val_acc: 0.2367\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4517 - acc: 0.4086 - val_loss: 2.0504 - val_acc: 0.2333\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4517 - acc: 0.4114 - val_loss: 2.0529 - val_acc: 0.2300\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4517 - acc: 0.4100 - val_loss: 2.0493 - val_acc: 0.2367\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4501 - acc: 0.4171 - val_loss: 2.0635 - val_acc: 0.2567\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4507 - acc: 0.4129 - val_loss: 2.0636 - val_acc: 0.2333\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4509 - acc: 0.4129 - val_loss: 2.0607 - val_acc: 0.2367\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0591 - val_acc: 0.2433\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0602 - val_acc: 0.2300\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4496 - acc: 0.4129 - val_loss: 2.0679 - val_acc: 0.2500\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4503 - acc: 0.4114 - val_loss: 2.0532 - val_acc: 0.2533\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 1.4495 - acc: 0.4114 - val_loss: 2.0730 - val_acc: 0.2333\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4479 - acc: 0.4186 - val_loss: 2.0679 - val_acc: 0.2533\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4492 - acc: 0.4043 - val_loss: 2.0617 - val_acc: 0.2400\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4481 - acc: 0.4114 - val_loss: 2.0706 - val_acc: 0.2333\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4485 - acc: 0.4157 - val_loss: 2.0574 - val_acc: 0.2300\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4487 - acc: 0.4157 - val_loss: 2.0743 - val_acc: 0.2333\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4478 - acc: 0.4114 - val_loss: 2.0718 - val_acc: 0.2367\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4471 - acc: 0.4186 - val_loss: 2.0687 - val_acc: 0.2267\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4480 - acc: 0.4171 - val_loss: 2.0681 - val_acc: 0.2333\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4478 - acc: 0.4043 - val_loss: 2.0748 - val_acc: 0.2367\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4472 - acc: 0.4114 - val_loss: 2.0543 - val_acc: 0.2367\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4478 - acc: 0.4257 - val_loss: 2.0637 - val_acc: 0.2333\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4458 - acc: 0.4129 - val_loss: 2.0510 - val_acc: 0.2367\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4476 - acc: 0.4100 - val_loss: 2.0619 - val_acc: 0.2333\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4459 - acc: 0.4114 - val_loss: 2.0546 - val_acc: 0.2333\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4468 - acc: 0.4114 - val_loss: 2.0822 - val_acc: 0.2367\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0754 - val_acc: 0.2400\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4458 - acc: 0.4129 - val_loss: 2.0814 - val_acc: 0.2333\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4456 - acc: 0.4143 - val_loss: 2.0716 - val_acc: 0.2333\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4445 - acc: 0.4071 - val_loss: 2.0652 - val_acc: 0.2567\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4464 - acc: 0.4143 - val_loss: 2.0671 - val_acc: 0.2333\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4451 - acc: 0.4100 - val_loss: 2.0682 - val_acc: 0.2367\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4452 - acc: 0.4129 - val_loss: 2.0812 - val_acc: 0.2300\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0812 - val_acc: 0.2233\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4441 - acc: 0.4186 - val_loss: 2.0584 - val_acc: 0.2367\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0755 - val_acc: 0.2467\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4450 - acc: 0.4100 - val_loss: 2.0817 - val_acc: 0.2433\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0851 - val_acc: 0.2300\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4440 - acc: 0.4143 - val_loss: 2.0723 - val_acc: 0.2367\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4432 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2333\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4415 - acc: 0.4114 - val_loss: 2.0704 - val_acc: 0.2567\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.4424 - acc: 0.4129 - val_loss: 2.0710 - val_acc: 0.2333\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 1.4431 - acc: 0.4086 - val_loss: 2.0866 - val_acc: 0.2333\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0831 - val_acc: 0.2333\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4433 - acc: 0.4171 - val_loss: 2.0739 - val_acc: 0.2333\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 140us/step - loss: 1.4419 - acc: 0.4157 - val_loss: 2.0894 - val_acc: 0.2400\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4430 - acc: 0.4143 - val_loss: 2.0744 - val_acc: 0.2333\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4417 - acc: 0.4186 - val_loss: 2.0781 - val_acc: 0.2467\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4415 - acc: 0.4157 - val_loss: 2.0638 - val_acc: 0.2467\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0746 - val_acc: 0.2533\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4426 - acc: 0.4086 - val_loss: 2.0864 - val_acc: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4409 - acc: 0.4157 - val_loss: 2.0802 - val_acc: 0.2300\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4410 - acc: 0.4114 - val_loss: 2.0783 - val_acc: 0.2333\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4405 - acc: 0.4186 - val_loss: 2.0804 - val_acc: 0.2433\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4408 - acc: 0.4129 - val_loss: 2.0792 - val_acc: 0.2367\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4419 - acc: 0.4100 - val_loss: 2.0768 - val_acc: 0.2367\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4410 - acc: 0.4000 - val_loss: 2.0803 - val_acc: 0.2367\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4403 - acc: 0.4157 - val_loss: 2.0962 - val_acc: 0.2367\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4394 - acc: 0.4171 - val_loss: 2.0836 - val_acc: 0.2400\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4397 - acc: 0.4143 - val_loss: 2.0882 - val_acc: 0.2333\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4390 - acc: 0.4200 - val_loss: 2.0811 - val_acc: 0.2533\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0752 - val_acc: 0.2367\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4375 - acc: 0.4157 - val_loss: 2.0910 - val_acc: 0.2567\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4382 - acc: 0.4171 - val_loss: 2.0936 - val_acc: 0.2333\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4394 - acc: 0.4157 - val_loss: 2.0816 - val_acc: 0.2367\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4378 - acc: 0.4157 - val_loss: 2.0813 - val_acc: 0.2533\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4384 - acc: 0.4114 - val_loss: 2.0824 - val_acc: 0.2400\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4386 - acc: 0.4214 - val_loss: 2.0823 - val_acc: 0.2400\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4375 - acc: 0.4114 - val_loss: 2.1034 - val_acc: 0.2433\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4367 - acc: 0.4200 - val_loss: 2.1026 - val_acc: 0.2533\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4369 - acc: 0.4171 - val_loss: 2.0803 - val_acc: 0.2600\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4360 - acc: 0.4143 - val_loss: 2.0999 - val_acc: 0.2300\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4356 - acc: 0.4214 - val_loss: 2.0731 - val_acc: 0.2333\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 1.4369 - acc: 0.4257 - val_loss: 2.0897 - val_acc: 0.2367\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4377 - acc: 0.4171 - val_loss: 2.0892 - val_acc: 0.2400\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4361 - acc: 0.4243 - val_loss: 2.0865 - val_acc: 0.2567\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4356 - acc: 0.4100 - val_loss: 2.0792 - val_acc: 0.2500\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4331 - acc: 0.4129 - val_loss: 2.0895 - val_acc: 0.2600\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0833 - val_acc: 0.2567\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4352 - acc: 0.4186 - val_loss: 2.1061 - val_acc: 0.2567\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4355 - acc: 0.4143 - val_loss: 2.0773 - val_acc: 0.2367\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.4356 - acc: 0.4157 - val_loss: 2.0845 - val_acc: 0.2400\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0921 - val_acc: 0.2400\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4345 - acc: 0.4157 - val_loss: 2.0994 - val_acc: 0.2333\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4337 - acc: 0.4243 - val_loss: 2.0962 - val_acc: 0.2333\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4340 - acc: 0.4186 - val_loss: 2.0836 - val_acc: 0.2400\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4347 - acc: 0.4171 - val_loss: 2.0828 - val_acc: 0.2400\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4334 - acc: 0.4186 - val_loss: 2.1091 - val_acc: 0.2467\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4348 - acc: 0.4157 - val_loss: 2.0881 - val_acc: 0.2567\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0993 - val_acc: 0.2333\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4336 - acc: 0.4171 - val_loss: 2.1075 - val_acc: 0.2500\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4334 - acc: 0.4229 - val_loss: 2.0955 - val_acc: 0.2433\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4328 - acc: 0.4200 - val_loss: 2.1005 - val_acc: 0.2400\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4328 - acc: 0.4186 - val_loss: 2.0964 - val_acc: 0.2467\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4318 - acc: 0.4186 - val_loss: 2.0925 - val_acc: 0.2433\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4327 - acc: 0.4129 - val_loss: 2.0985 - val_acc: 0.2367\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.1142 - val_acc: 0.2300\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4326 - acc: 0.4200 - val_loss: 2.0939 - val_acc: 0.2433\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4321 - acc: 0.4157 - val_loss: 2.0875 - val_acc: 0.2400\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4321 - acc: 0.4214 - val_loss: 2.0809 - val_acc: 0.2400\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4315 - acc: 0.4243 - val_loss: 2.1026 - val_acc: 0.2367\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4315 - acc: 0.4200 - val_loss: 2.0936 - val_acc: 0.2333\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4297 - acc: 0.4214 - val_loss: 2.1149 - val_acc: 0.2533\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 198us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.0973 - val_acc: 0.2467\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4305 - acc: 0.4214 - val_loss: 2.0961 - val_acc: 0.2367\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4301 - acc: 0.4186 - val_loss: 2.1015 - val_acc: 0.2567\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4309 - acc: 0.4200 - val_loss: 2.0852 - val_acc: 0.2400\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4303 - acc: 0.4257 - val_loss: 2.0994 - val_acc: 0.2367\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4282 - acc: 0.4243 - val_loss: 2.0936 - val_acc: 0.2600\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4307 - acc: 0.4186 - val_loss: 2.0989 - val_acc: 0.2367\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4297 - acc: 0.4157 - val_loss: 2.1004 - val_acc: 0.2367\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4290 - acc: 0.4200 - val_loss: 2.1235 - val_acc: 0.2533\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4301 - acc: 0.4200 - val_loss: 2.1141 - val_acc: 0.2400\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.4297 - acc: 0.4200 - val_loss: 2.1038 - val_acc: 0.2367\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4291 - acc: 0.4200 - val_loss: 2.1034 - val_acc: 0.2433\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4286 - acc: 0.4214 - val_loss: 2.1027 - val_acc: 0.2367\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4283 - acc: 0.4200 - val_loss: 2.0944 - val_acc: 0.2400\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 1.4282 - acc: 0.4229 - val_loss: 2.1103 - val_acc: 0.2367\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4278 - acc: 0.4243 - val_loss: 2.1169 - val_acc: 0.2433\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4277 - acc: 0.4243 - val_loss: 2.0984 - val_acc: 0.2367\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4274 - acc: 0.4229 - val_loss: 2.1266 - val_acc: 0.2333\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4275 - acc: 0.4214 - val_loss: 2.0957 - val_acc: 0.2400\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.4270 - acc: 0.4229 - val_loss: 2.1199 - val_acc: 0.2467\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4270 - acc: 0.4243 - val_loss: 2.1239 - val_acc: 0.2400\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4277 - acc: 0.4129 - val_loss: 2.1104 - val_acc: 0.2367\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4261 - acc: 0.4243 - val_loss: 2.1081 - val_acc: 0.2400\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4264 - acc: 0.4286 - val_loss: 2.1092 - val_acc: 0.2333\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4274 - acc: 0.4214 - val_loss: 2.1141 - val_acc: 0.2400\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4261 - acc: 0.4300 - val_loss: 2.1087 - val_acc: 0.2367\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4248 - acc: 0.4314 - val_loss: 2.1025 - val_acc: 0.2367\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4266 - acc: 0.4229 - val_loss: 2.1184 - val_acc: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4266 - acc: 0.4200 - val_loss: 2.1076 - val_acc: 0.2467\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4252 - acc: 0.4229 - val_loss: 2.1182 - val_acc: 0.2367\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4250 - acc: 0.4243 - val_loss: 2.1058 - val_acc: 0.2400\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.4249 - acc: 0.4200 - val_loss: 2.1197 - val_acc: 0.2567\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4253 - acc: 0.4157 - val_loss: 2.1015 - val_acc: 0.2533\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4241 - acc: 0.4286 - val_loss: 2.1046 - val_acc: 0.2533\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4258 - acc: 0.4200 - val_loss: 2.1048 - val_acc: 0.2433\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4221 - acc: 0.4329 - val_loss: 2.1161 - val_acc: 0.2533\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4254 - acc: 0.4300 - val_loss: 2.1062 - val_acc: 0.2400\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4250 - acc: 0.4186 - val_loss: 2.1095 - val_acc: 0.2433\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4231 - acc: 0.4271 - val_loss: 2.1295 - val_acc: 0.2600\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4223 - acc: 0.4257 - val_loss: 2.0972 - val_acc: 0.2333\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1023 - val_acc: 0.2333\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4225 - acc: 0.4157 - val_loss: 2.1138 - val_acc: 0.2400\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4235 - acc: 0.4243 - val_loss: 2.1171 - val_acc: 0.2367\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4222 - acc: 0.4257 - val_loss: 2.1341 - val_acc: 0.2333\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4237 - acc: 0.4257 - val_loss: 2.1211 - val_acc: 0.2367\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4221 - acc: 0.4386 - val_loss: 2.1169 - val_acc: 0.2467\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4223 - acc: 0.4143 - val_loss: 2.1147 - val_acc: 0.2400\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4232 - acc: 0.4229 - val_loss: 2.1210 - val_acc: 0.2433\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4220 - acc: 0.4300 - val_loss: 2.1191 - val_acc: 0.2433\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.1147 - val_acc: 0.2400\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4219 - acc: 0.4357 - val_loss: 2.1130 - val_acc: 0.2400\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4215 - acc: 0.4214 - val_loss: 2.1356 - val_acc: 0.2500\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4226 - acc: 0.4300 - val_loss: 2.1280 - val_acc: 0.2400\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4216 - acc: 0.4186 - val_loss: 2.1158 - val_acc: 0.2400\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4223 - acc: 0.4300 - val_loss: 2.1311 - val_acc: 0.2433\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4202 - acc: 0.4186 - val_loss: 2.1424 - val_acc: 0.2367\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4219 - acc: 0.4200 - val_loss: 2.1169 - val_acc: 0.2400\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4540 - acc: 0.417 - 0s 138us/step - loss: 1.4218 - acc: 0.4229 - val_loss: 2.1170 - val_acc: 0.2367\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4205 - acc: 0.4271 - val_loss: 2.1066 - val_acc: 0.2400\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 147us/step - loss: 1.4206 - acc: 0.4229 - val_loss: 2.1179 - val_acc: 0.2333\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4201 - acc: 0.4229 - val_loss: 2.1091 - val_acc: 0.2333\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4196 - acc: 0.4229 - val_loss: 2.1236 - val_acc: 0.2367\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.4202 - acc: 0.4243 - val_loss: 2.1251 - val_acc: 0.2433\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4201 - acc: 0.4229 - val_loss: 2.1323 - val_acc: 0.2500\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4191 - acc: 0.4243 - val_loss: 2.1295 - val_acc: 0.2400\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4182 - acc: 0.4286 - val_loss: 2.1298 - val_acc: 0.2533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4194 - acc: 0.4300 - val_loss: 2.1246 - val_acc: 0.2467\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4178 - acc: 0.4271 - val_loss: 2.1345 - val_acc: 0.2333\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4192 - acc: 0.4214 - val_loss: 2.1240 - val_acc: 0.2367\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4193 - acc: 0.4286 - val_loss: 2.1251 - val_acc: 0.2333\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4055 - acc: 0.440 - 0s 133us/step - loss: 1.4189 - acc: 0.4257 - val_loss: 2.1179 - val_acc: 0.2400\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1304 - val_acc: 0.2500\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4185 - acc: 0.4243 - val_loss: 2.1065 - val_acc: 0.2433\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4187 - acc: 0.4329 - val_loss: 2.1284 - val_acc: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4182 - acc: 0.4329 - val_loss: 2.1311 - val_acc: 0.2433\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4180 - acc: 0.4271 - val_loss: 2.1414 - val_acc: 0.2367\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4180 - acc: 0.4243 - val_loss: 2.1248 - val_acc: 0.2467\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4184 - acc: 0.4214 - val_loss: 2.1138 - val_acc: 0.2467\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1239 - val_acc: 0.2433\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1257 - val_acc: 0.2400\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4175 - acc: 0.4314 - val_loss: 2.1285 - val_acc: 0.2400\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4164 - acc: 0.4286 - val_loss: 2.1316 - val_acc: 0.2533\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4171 - acc: 0.4214 - val_loss: 2.1210 - val_acc: 0.2367\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4165 - acc: 0.4271 - val_loss: 2.1359 - val_acc: 0.2500\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4169 - acc: 0.4286 - val_loss: 2.1313 - val_acc: 0.2367\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4165 - acc: 0.4329 - val_loss: 2.1275 - val_acc: 0.2400\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4160 - acc: 0.4314 - val_loss: 2.1291 - val_acc: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1358 - val_acc: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4162 - acc: 0.4357 - val_loss: 2.1371 - val_acc: 0.2400\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4153 - acc: 0.4314 - val_loss: 2.1292 - val_acc: 0.2567\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4159 - acc: 0.4200 - val_loss: 2.1395 - val_acc: 0.2333\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4159 - acc: 0.4329 - val_loss: 2.1355 - val_acc: 0.2333\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4158 - acc: 0.4329 - val_loss: 2.1721 - val_acc: 0.2400\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4146 - acc: 0.4271 - val_loss: 2.1339 - val_acc: 0.2600\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.4148 - acc: 0.4257 - val_loss: 2.1275 - val_acc: 0.2433\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4143 - acc: 0.4314 - val_loss: 2.1287 - val_acc: 0.2467\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4149 - acc: 0.4357 - val_loss: 2.1288 - val_acc: 0.2400\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4149 - acc: 0.4386 - val_loss: 2.1292 - val_acc: 0.2400\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4144 - acc: 0.4314 - val_loss: 2.1349 - val_acc: 0.2400\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4150 - acc: 0.4229 - val_loss: 2.1251 - val_acc: 0.2367\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3985 - acc: 0.429 - 0s 144us/step - loss: 1.4139 - acc: 0.4343 - val_loss: 2.1366 - val_acc: 0.2367\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1357 - val_acc: 0.2433\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4141 - acc: 0.4271 - val_loss: 2.1262 - val_acc: 0.2400\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4138 - acc: 0.4329 - val_loss: 2.1379 - val_acc: 0.2367\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4129 - acc: 0.4271 - val_loss: 2.1431 - val_acc: 0.2567\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4141 - acc: 0.4300 - val_loss: 2.1374 - val_acc: 0.2467\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4135 - acc: 0.4286 - val_loss: 2.1291 - val_acc: 0.2367\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4118 - acc: 0.4286 - val_loss: 2.1355 - val_acc: 0.2367\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4124 - acc: 0.4271 - val_loss: 2.1429 - val_acc: 0.2367\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4110 - acc: 0.4357 - val_loss: 2.1507 - val_acc: 0.2600\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4131 - acc: 0.4329 - val_loss: 2.1424 - val_acc: 0.2600\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4048 - acc: 0.439 - 0s 132us/step - loss: 1.4131 - acc: 0.4314 - val_loss: 2.1460 - val_acc: 0.2467\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1388 - val_acc: 0.2367\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4117 - acc: 0.4257 - val_loss: 2.1437 - val_acc: 0.2433\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4109 - acc: 0.4300 - val_loss: 2.1457 - val_acc: 0.2433\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4112 - acc: 0.4314 - val_loss: 2.1577 - val_acc: 0.2467\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4124 - acc: 0.4243 - val_loss: 2.1485 - val_acc: 0.2467\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 148us/step - loss: 1.4112 - acc: 0.4300 - val_loss: 2.1481 - val_acc: 0.2400\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4116 - acc: 0.4357 - val_loss: 2.1391 - val_acc: 0.2367\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4111 - acc: 0.4357 - val_loss: 2.1430 - val_acc: 0.2433\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4104 - acc: 0.4271 - val_loss: 2.1460 - val_acc: 0.2400\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4104 - acc: 0.4457 - val_loss: 2.1634 - val_acc: 0.2467\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4112 - acc: 0.4329 - val_loss: 2.1604 - val_acc: 0.2500\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4110 - acc: 0.4229 - val_loss: 2.1649 - val_acc: 0.2467\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.4107 - acc: 0.4343 - val_loss: 2.1746 - val_acc: 0.2400\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4097 - acc: 0.4286 - val_loss: 2.1433 - val_acc: 0.2367\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4098 - acc: 0.4300 - val_loss: 2.1515 - val_acc: 0.2467\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1380 - val_acc: 0.2433\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4106 - acc: 0.4300 - val_loss: 2.1504 - val_acc: 0.2400\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4088 - acc: 0.4314 - val_loss: 2.1466 - val_acc: 0.2367\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4081 - acc: 0.4329 - val_loss: 2.1411 - val_acc: 0.2433\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4093 - acc: 0.4371 - val_loss: 2.1470 - val_acc: 0.2367\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1591 - val_acc: 0.2500\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4090 - acc: 0.4286 - val_loss: 2.1476 - val_acc: 0.2367\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4081 - acc: 0.4300 - val_loss: 2.1614 - val_acc: 0.2400\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4087 - acc: 0.4300 - val_loss: 2.1371 - val_acc: 0.2367\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4092 - acc: 0.4357 - val_loss: 2.1480 - val_acc: 0.2400\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4075 - acc: 0.4243 - val_loss: 2.1565 - val_acc: 0.2467\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4081 - acc: 0.4371 - val_loss: 2.1526 - val_acc: 0.2533\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4085 - acc: 0.4300 - val_loss: 2.1522 - val_acc: 0.2400\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4070 - acc: 0.4314 - val_loss: 2.1476 - val_acc: 0.2367\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4070 - acc: 0.4257 - val_loss: 2.1467 - val_acc: 0.2333\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4087 - acc: 0.4357 - val_loss: 2.1504 - val_acc: 0.2433\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4068 - acc: 0.4314 - val_loss: 2.1516 - val_acc: 0.2367\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4046 - acc: 0.4343 - val_loss: 2.1744 - val_acc: 0.2633\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.4074 - acc: 0.4229 - val_loss: 2.1518 - val_acc: 0.2333\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4075 - acc: 0.4357 - val_loss: 2.1607 - val_acc: 0.2500\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4067 - acc: 0.4271 - val_loss: 2.1585 - val_acc: 0.2467\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4069 - acc: 0.4343 - val_loss: 2.1547 - val_acc: 0.2367\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4051 - acc: 0.4357 - val_loss: 2.1550 - val_acc: 0.2367\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4058 - acc: 0.4357 - val_loss: 2.1783 - val_acc: 0.2533\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4063 - acc: 0.4371 - val_loss: 2.1643 - val_acc: 0.2433\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4074 - acc: 0.4271 - val_loss: 2.1668 - val_acc: 0.2500\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4055 - acc: 0.4314 - val_loss: 2.1697 - val_acc: 0.2500\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4055 - acc: 0.4386 - val_loss: 2.1627 - val_acc: 0.2533\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4047 - acc: 0.4357 - val_loss: 2.1692 - val_acc: 0.2633\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4048 - acc: 0.4357 - val_loss: 2.1385 - val_acc: 0.2433\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.4053 - acc: 0.4357 - val_loss: 2.1671 - val_acc: 0.2433\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4056 - acc: 0.4343 - val_loss: 2.1573 - val_acc: 0.2400\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4049 - acc: 0.4400 - val_loss: 2.1576 - val_acc: 0.2400\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4035 - acc: 0.4343 - val_loss: 2.1711 - val_acc: 0.2467\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4049 - acc: 0.4286 - val_loss: 2.1752 - val_acc: 0.2467\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4036 - acc: 0.4371 - val_loss: 2.1603 - val_acc: 0.2567\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4043 - acc: 0.4314 - val_loss: 2.1425 - val_acc: 0.2367\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4048 - acc: 0.4343 - val_loss: 2.1528 - val_acc: 0.2367\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4039 - acc: 0.4343 - val_loss: 2.1742 - val_acc: 0.2467\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4036 - acc: 0.4357 - val_loss: 2.1517 - val_acc: 0.2433\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4036 - acc: 0.4257 - val_loss: 2.1732 - val_acc: 0.2333\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4043 - acc: 0.4314 - val_loss: 2.1596 - val_acc: 0.2367\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4013 - acc: 0.4343 - val_loss: 2.1707 - val_acc: 0.2400\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4052 - acc: 0.4329 - val_loss: 2.1569 - val_acc: 0.2400\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4034 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2500\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4036 - acc: 0.4371 - val_loss: 2.1715 - val_acc: 0.2433\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4044 - acc: 0.4271 - val_loss: 2.1499 - val_acc: 0.2367\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 1.4026 - acc: 0.4343 - val_loss: 2.1802 - val_acc: 0.2533\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4031 - acc: 0.4300 - val_loss: 2.1447 - val_acc: 0.2433\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 157us/step - loss: 1.4034 - acc: 0.4386 - val_loss: 2.1684 - val_acc: 0.2467\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4027 - acc: 0.4371 - val_loss: 2.1610 - val_acc: 0.2400\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4027 - acc: 0.4329 - val_loss: 2.1645 - val_acc: 0.2400\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4011 - acc: 0.4429 - val_loss: 2.1767 - val_acc: 0.2600\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4027 - acc: 0.4371 - val_loss: 2.1676 - val_acc: 0.2567\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4024 - acc: 0.4257 - val_loss: 2.1699 - val_acc: 0.2433\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4022 - acc: 0.4371 - val_loss: 2.1742 - val_acc: 0.2433\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4020 - acc: 0.4357 - val_loss: 2.1782 - val_acc: 0.2467\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.4020 - acc: 0.4429 - val_loss: 2.1662 - val_acc: 0.2400\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.4012 - acc: 0.4343 - val_loss: 2.1687 - val_acc: 0.2467\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4015 - acc: 0.4357 - val_loss: 2.1732 - val_acc: 0.2600\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4016 - acc: 0.4343 - val_loss: 2.1695 - val_acc: 0.2533\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4011 - acc: 0.4386 - val_loss: 2.1872 - val_acc: 0.2400\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4016 - acc: 0.4329 - val_loss: 2.1623 - val_acc: 0.2467\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4001 - acc: 0.4457 - val_loss: 2.1650 - val_acc: 0.2467\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3999 - acc: 0.4386 - val_loss: 2.1776 - val_acc: 0.2533\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4003 - acc: 0.4329 - val_loss: 2.1672 - val_acc: 0.2467\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3993 - acc: 0.4371 - val_loss: 2.1839 - val_acc: 0.2633\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3991 - acc: 0.4357 - val_loss: 2.1644 - val_acc: 0.2367\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4009 - acc: 0.4400 - val_loss: 2.1603 - val_acc: 0.2367\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3999 - acc: 0.4371 - val_loss: 2.1573 - val_acc: 0.2367\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4005 - acc: 0.4357 - val_loss: 2.1810 - val_acc: 0.2467\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3998 - acc: 0.4414 - val_loss: 2.1742 - val_acc: 0.2433\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.3994 - acc: 0.4343 - val_loss: 2.1787 - val_acc: 0.2500\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.4004 - acc: 0.4371 - val_loss: 2.1611 - val_acc: 0.2367\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3991 - acc: 0.4371 - val_loss: 2.1791 - val_acc: 0.2367\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3997 - acc: 0.4414 - val_loss: 2.1686 - val_acc: 0.2367\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4000 - acc: 0.4386 - val_loss: 2.1882 - val_acc: 0.2433\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.1860 - val_acc: 0.2567\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3991 - acc: 0.4343 - val_loss: 2.1746 - val_acc: 0.2467\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.3989 - acc: 0.4400 - val_loss: 2.1797 - val_acc: 0.2433\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3979 - acc: 0.4400 - val_loss: 2.1792 - val_acc: 0.2400\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3971 - acc: 0.4371 - val_loss: 2.1788 - val_acc: 0.2533\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3985 - acc: 0.4300 - val_loss: 2.1870 - val_acc: 0.2433\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3989 - acc: 0.4329 - val_loss: 2.1696 - val_acc: 0.2500\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3984 - acc: 0.4371 - val_loss: 2.1712 - val_acc: 0.2400\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3968 - acc: 0.4414 - val_loss: 2.1862 - val_acc: 0.2500\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3966 - acc: 0.4386 - val_loss: 2.1703 - val_acc: 0.2567\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3988 - acc: 0.4414 - val_loss: 2.1763 - val_acc: 0.2467\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3970 - acc: 0.4329 - val_loss: 2.1817 - val_acc: 0.2367\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3972 - acc: 0.4443 - val_loss: 2.1772 - val_acc: 0.2467\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3975 - acc: 0.4357 - val_loss: 2.1776 - val_acc: 0.2400\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.3972 - acc: 0.4400 - val_loss: 2.1913 - val_acc: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3972 - acc: 0.4414 - val_loss: 2.1919 - val_acc: 0.2400\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3974 - acc: 0.4357 - val_loss: 2.1858 - val_acc: 0.2500\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3967 - acc: 0.4343 - val_loss: 2.1806 - val_acc: 0.2467\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3962 - acc: 0.4400 - val_loss: 2.1719 - val_acc: 0.2500\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3965 - acc: 0.4329 - val_loss: 2.1823 - val_acc: 0.2467\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3958 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2500\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3965 - acc: 0.4443 - val_loss: 2.1847 - val_acc: 0.2467\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3962 - acc: 0.4443 - val_loss: 2.1892 - val_acc: 0.2500\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3961 - acc: 0.4429 - val_loss: 2.1820 - val_acc: 0.2367\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3954 - acc: 0.4457 - val_loss: 2.1933 - val_acc: 0.2500\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3953 - acc: 0.4386 - val_loss: 2.1976 - val_acc: 0.2500\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3960 - acc: 0.4343 - val_loss: 2.1783 - val_acc: 0.2333\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3956 - acc: 0.4343 - val_loss: 2.1832 - val_acc: 0.2400\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3948 - acc: 0.4357 - val_loss: 2.1670 - val_acc: 0.2333\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3955 - acc: 0.4400 - val_loss: 2.1922 - val_acc: 0.2433\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3944 - acc: 0.4357 - val_loss: 2.1948 - val_acc: 0.2467\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 142us/step - loss: 1.3947 - acc: 0.4329 - val_loss: 2.1898 - val_acc: 0.2467\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3946 - acc: 0.4329 - val_loss: 2.1853 - val_acc: 0.2467\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3939 - acc: 0.4386 - val_loss: 2.1954 - val_acc: 0.2533\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3942 - acc: 0.4271 - val_loss: 2.1755 - val_acc: 0.2367\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3938 - acc: 0.4457 - val_loss: 2.1756 - val_acc: 0.2367\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3930 - acc: 0.4414 - val_loss: 2.1839 - val_acc: 0.2367\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3940 - acc: 0.4429 - val_loss: 2.1895 - val_acc: 0.2500\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3939 - acc: 0.4414 - val_loss: 2.1858 - val_acc: 0.2467\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3937 - acc: 0.4357 - val_loss: 2.1979 - val_acc: 0.2533\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3940 - acc: 0.4429 - val_loss: 2.1872 - val_acc: 0.2500\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3936 - acc: 0.4457 - val_loss: 2.1965 - val_acc: 0.2500\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3930 - acc: 0.4400 - val_loss: 2.2012 - val_acc: 0.2433\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3921 - acc: 0.4400 - val_loss: 2.1855 - val_acc: 0.2433\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3938 - acc: 0.4329 - val_loss: 2.2131 - val_acc: 0.2467\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.3935 - acc: 0.4386 - val_loss: 2.1817 - val_acc: 0.2467\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3930 - acc: 0.4400 - val_loss: 2.1929 - val_acc: 0.2433\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3924 - acc: 0.4443 - val_loss: 2.1686 - val_acc: 0.2467\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3933 - acc: 0.4400 - val_loss: 2.1900 - val_acc: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3924 - acc: 0.4414 - val_loss: 2.1859 - val_acc: 0.2500\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3921 - acc: 0.4371 - val_loss: 2.1886 - val_acc: 0.2500\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3913 - acc: 0.4414 - val_loss: 2.1871 - val_acc: 0.2533\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3924 - acc: 0.4429 - val_loss: 2.2044 - val_acc: 0.2533\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3925 - acc: 0.4400 - val_loss: 2.1931 - val_acc: 0.2467\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1866 - val_acc: 0.2400\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3917 - acc: 0.4386 - val_loss: 2.1910 - val_acc: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3916 - acc: 0.4371 - val_loss: 2.2008 - val_acc: 0.2400\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3916 - acc: 0.4414 - val_loss: 2.1866 - val_acc: 0.2467\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.3913 - acc: 0.4386 - val_loss: 2.1940 - val_acc: 0.2367\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3902 - acc: 0.4429 - val_loss: 2.1889 - val_acc: 0.2500\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3909 - acc: 0.4357 - val_loss: 2.1963 - val_acc: 0.2500\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3909 - acc: 0.4429 - val_loss: 2.2034 - val_acc: 0.2500\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3906 - acc: 0.4443 - val_loss: 2.1921 - val_acc: 0.2533\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3907 - acc: 0.4357 - val_loss: 2.1894 - val_acc: 0.2400\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3900 - acc: 0.4457 - val_loss: 2.1944 - val_acc: 0.2533\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3907 - acc: 0.4414 - val_loss: 2.1928 - val_acc: 0.2467\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.2049 - val_acc: 0.2500\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3895 - acc: 0.4386 - val_loss: 2.2127 - val_acc: 0.2500\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3903 - acc: 0.4400 - val_loss: 2.1968 - val_acc: 0.2533\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3899 - acc: 0.4357 - val_loss: 2.2018 - val_acc: 0.2500\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1945 - val_acc: 0.2500\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3892 - acc: 0.4429 - val_loss: 2.2079 - val_acc: 0.2367\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3893 - acc: 0.4414 - val_loss: 2.2006 - val_acc: 0.2500\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3888 - acc: 0.4429 - val_loss: 2.1918 - val_acc: 0.2367\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3888 - acc: 0.4457 - val_loss: 2.2146 - val_acc: 0.2633\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3903 - acc: 0.4343 - val_loss: 2.2113 - val_acc: 0.2533\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3887 - acc: 0.4429 - val_loss: 2.2219 - val_acc: 0.2500\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.3890 - acc: 0.4457 - val_loss: 2.1941 - val_acc: 0.2433\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3888 - acc: 0.4371 - val_loss: 2.2055 - val_acc: 0.2400\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3886 - acc: 0.4443 - val_loss: 2.2005 - val_acc: 0.2533\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3885 - acc: 0.4371 - val_loss: 2.1873 - val_acc: 0.2333\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3891 - acc: 0.4429 - val_loss: 2.2025 - val_acc: 0.2500\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3879 - acc: 0.4443 - val_loss: 2.2049 - val_acc: 0.2467\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3881 - acc: 0.4429 - val_loss: 2.2014 - val_acc: 0.2500\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3884 - acc: 0.4414 - val_loss: 2.2143 - val_acc: 0.2533\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3879 - acc: 0.4386 - val_loss: 2.2010 - val_acc: 0.2500\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3880 - acc: 0.4414 - val_loss: 2.2118 - val_acc: 0.2500\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEKCAYAAAChTwphAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzsnXd4FOX2x78nISGUEIqAIB0sdJBirggIKoJcEVSkSpGrF8u1gCio14YKAj8LiiIqRRAQQRGkipcqvXekQ2gJLYXU3T2/P87Ozuzu7O5ssiEkeT/PM8/OzFvmnc1mzpz3PYWYGQqFQqFQ5AfC8noACoVCoVBYRQkthUKhUOQblNBSKBQKRb5BCS2FQqFQ5BuU0FIoFApFvkEJLYVCoVDkG5TQUigUCkW+QQkthUKhUOQblNBSKBQKRb6hSF4PIFjCwsK4WLFieT0MhUKhyFekpqYyM+d7RSXfCa1ixYrh2rVreT0MhUKhyFcQUVpejyEU5Hupq1AoFIrCgxJaCoVCocg3KKGlUCgUCgAAEXUkokNEdISIhvup9zgRMRE1dx7XIKI0Itrp3Cbm1hjz3ZqWGVlZWYiLi0N6enpeDyXfEhUVhSpVqiAiIiKvh6JQKPIAIgoHMAHAAwDiAGwhogXMvN+jXjSAFwFs8ujiKDM3ye1xFgihFRcXh+joaNSoUQNElNfDyXcwMy5duoS4uDjUrFkzr4ejUCjyhpYAjjDzMQAgotkAHgGw36PeSABjALx6fYcnFIjpwfT0dJQrV04JrGxCRChXrpzSVBWKgk0RItpq2J7xKL8FwGnDcZzznAsiagqgKjP/btJ/TSLaQUSriah1aIeuUyA0LQBKYOUQ9f0pFAUeGzM391Nu9hBwpbYnojAAnwIYYFLvHIBqzHyJiJoBmE9E9Zk5KScDNqNAaFpWsNvTkJFxBg5HVl4PRaFQXAfi44F580Lb56VLwJw51uuvXAnsd06unTkDLFgA7N4NrF1rXn/PHr3s4EFg3Dhgw4acjTkI4gBUNRxXAXDWcBwNoAGAVUR0AkAsgAVE1JyZM5j5EgAw8zYARwHcliujZOZ8tRUvXpw92b9/v9c5TzIzL3FS0ha22a4FrBssV65c4QkTJmSrbadOnfjKlSuW67/zzjs8duzYbF0rEFa+R4Uiv/CPfzADzBcvhq7PDh2kz5MnzctPn2b+7TfZX7VK6gJyXL++fgwwr1zJvHev3jY93b2+se6YMczXcvjoAnCN/TxbITNvxwDUBBAJYBeA+n7qrwLQ3LlfHkC4c78WgDMAyvq7Xna3QqNpiWYLGLTdkHH16lV89dVXpmV2u91v28WLF6N06dIhH5NCUdg5flw+MzJy1s+GDcDWrcDkycDJk3IuMdG8bps2wCOPAA4HcO+97mXnzrkft2sHNGgAfP89YLcDZcvqZZs3u9d97TXgvfdydBsBYWYbgBcALANwAMAcZt5HRO8TUZcAzdsA2E1EuwDMBTCYmS/nxjgLjdDSbpXZEfKehw8fjqNHj6JJkyYYNmwYVq1ahXbt2qF3795o2LAhAKBr165o1qwZ6tevj0mTJrna1qhRAxcvXsSJEydQt25dPP3006hfvz46dOiAtDT/UVd27tyJ2NhYNGrUCN26dcOVK1cAAOPHj0e9evXQqFEj9OzZEwCwevVqNGnSBE2aNEHTpk2RnJwc8u9BobiRKOJcsc+O0LLbRZhkZQF33w20aAEMGgQcOiTl164Bv/0G/PILsH27nNu6VReUc+d69xkVZX6tf/0LuPNOIDVVP3fXXd71xowBVqwI/l6CgZkXM/NtzFybmT90nnubmReY1L2Xmbc69+cxc31mbszMdzLzwtwaY4ExxNA4fPhlpKTs9DrPbIfDkYqwsOIQdwTrlCzZBLfe+pnP8tGjR2Pv3r3YuVOuu2rVKmzevBl79+51mZBPnjwZZcuWRVpaGlq0aIHHHnsM5cqV8xj7YcyaNQvffvstnnjiCcybNw99+/b1ed1+/frhiy++QNu2bfH222/jvffew2effYbRo0fj+PHjKFq0KK5evQoAGDduHCZMmIBWrVohJSUFUb7+gxSKAoImtIzCwB9//glUqQLcfjswe7YIk/Pnzev+8APw9df68dixwLBh+nGPHvp+tWrA1KlAs2bAWeMKkYHdu62Ncc0a4P77rdUtqBQaTUs3jgv99KAZLVu2dPN5Gj9+PBo3bozY2FicPn0ahw8f9mpTs2ZNNGkivnnNmjXDiRMnfPafmJiIq1evom3btgCA/v37Y82aNQCARo0aoU+fPpgxYwaKOP9zW7VqhSFDhmD8+PG4evWq67xCkZf8/Tfwv/9lv/3GjcC2beZl2k88wIQFrlwBZs4UYXDHHXJOE3S+DDmMAgtwF1hGoqKAU6eAgQOBhSHQPUqUyHkf+Z0C9+TypRHZ7WlITd2HqKhaiIgoa1onlJQw/LpWrVqFFStWYMOGDShevDjuvfdeU5+ookWLuvbDw8MDTg/6YtGiRVizZg0WLFiAkSNHYt++fRg+fDg6d+6MxYsXIzY2FitWrMAd2n+oQpFH3H67fHI23yX/8Q/f7cOdEyqpqcDVq8CSJcDjjwPTpwMDBgBhYVJW1uNxcOoUULy47O/Ykb1xadSoIVaAoaJbt9D1lV8pPJpWajqKnodMUoeY6Ohov2tEiYmJKFOmDIoXL46DBw9i48aNOb5mTEwMypQpg7VO+9jp06ejbdu2cDgcOH36NNq1a4cxY8bg6tWrSElJwdGjR9GwYUO8/vrraN68OQ6G8j9Jocghs2eLxmOFuDgxHXeYLE9Pnw4kJQGXL+vrT6mpQM+eQO/eQMOGsjb10EPAr7+aay7VqwOrVmX7Vty4LYDRd+XKwPPP60LSF506iWAO1F9hoMBpWj7JsiEyEciqaAt51+XKlUOrVq3QoEEDdOrUCZ07d3Yr79ixIyZOnIhGjRrh9ttvR2xsbEiuO23aNAwePBipqamoVasWpkyZArvdjr59+yIxMRHMjFdeeQWlS5fGf//7X6xcuRLh4eGoV68eOnXqFJIxKBShoFcvsbqbPz9w3Q4dgAMHdKMHQHyhwsKAfv2ALl2kjsbcucCuXbKvCbJly2TzxXffBX8PZtSu7b/8zBn5/PJLqXvsGPDKK8CnnwI33yxratO+voZ+g9W8oIvcsKPPzS27flqOK5eYt2zhzMunAtYtrCg/LcX1YO9e8WFidvdFat7cvP433zBv2CD7CQl6/bZt3dvPn6/v//e/7mXFirkfh2IbNIi5VSvmBg1815k6lblUKfdzxvv2x5ql18QnrO2TIfneEcBPK79shWZ60DXB7fDvN6VQKELPlSsydQeIb5KnDxMAmCUYuHAB+Pe/RXNatEjWpDRWr3av27Wrvj9ypHuZleXhAQP8l/fuLdOKWt3vvgPWrZMoFhrlywN9+4o5PAA8/LD4dA0e7N5Xx9bX0OV+HxnYz50Dzp1D6z1fgUGodnQlsH49MHRozp3OCgC5Nj1IRFUB/ADgZgAOAJOY+XOPOn0AvO48TAHwLDPvypUBhTlv1WwiXKFQ5CoPPSSWfu3a6eeueTyzN2yQ6bvbbwdsNmDKFECbSU9OBv75z9wdo8EOyieLFvkvP3dOfz9mg3HI118DEw0ZppasLencM7EgqVzZ/TgmBmjVSu/0k08CD7QAk5ualg3AUGauC4lR9TwR1fOocxxAW2ZuBAl3Pwm5BIU5b1UJLYXiupKeLgILEAMJjY8+8q6rGbR+/TXwzDNAo0a5Pz6NyEjz8/4sFDVeeknGGh6cC6gYhi1dKvsZGWLm6Mm+ffp+TEyQFyh45JrQYuZzzLzduZ8MCQtyi0ed9cys2QxthARozB1c04NKaCkU15O33tL3jYLKTGgBYrm33zODUw7Rpib9oU0Phnk8FZ97LnDbzz7TjT0CosWCAoDRo8U0sGNHCbtRpoz/tipJ6/VZ0yKiGgCawjvTpZFBAJb4aP+MlgPGZsum9Z/StBSFlL//lmgP2WXTJt8OvJ788IO3smD0o/fjL++iXTtzhcMKvhSRrl2BkiXNyyIjgfHjJZQSs0SwAGQ6slat7I3DxcyZQP/+wOnTaHF7Enp1vCzOWxqaCeSyZe6LY74YNCiHAyoA5LalB4CSALYBeNRPnXYQTaxcoP6yaz3IdrtYD57aF7huIUVZDxZMrFiqWWm/z/mvM2MGc2KiXp6Vxfztt8x//y312rSR86tXM3/1VWgt9nxtvXrp46lWzbvc8160rXNn7/udNk3KUlPl+NQpOdYsHgOyfDnzrFnmF/Tc2rWzfpM5BMp6MDBEFAFgHoAfmfkXH3UaAfgOwCPszMeSS4ORJc8bRNMq6eO1z9d5hSKvqV9flIG+fSUu32+/iQbWoQPw9NO64+uaNfKUve8+a1NrOWHWLPk0xgw4eVKchseO9a7/+uvi/7TAGf6VTdap+vWT88WKyXHVqnLcti0kmVZ8vF5561a5yYMHxUrjwgX5Qnr1ErUzECtXmp8/cEAG+sILgfsobOSWNIRkwfwBwGd+6lQDcATA3Vb7zbamxcyObVs48+huS3VzmxIlSgR1/nqgNK2CSXZf1A8fZl6yxP1lf8sW+Sxe3L9SsGiRdQUiJ1tcnHz++af5PdSvL/5Unpw/L+2WLvVx88ePMxctyrxrl34uPl6/8KuvyuxN9+6hvaEpU5hPnHAfS4cOzAMHBv8H9AAFRNPKvY6BewAwgN0Adjq3hwAMhuRaAUTDumIo3xqo35wILfuOrZx1ZFfgikHy2muvuSWBfOedd3jcuHGcnJzM7du356ZNm3KDBg14/vz5rjqBhJbD4eBXX32V69evzw0aNODZs2czM/PZs2e5devW3LhxY65fvz6vWbOGbTYb9+/f31X3k08+ydZ9KKFVMNGehw6HtfpbtzJv3Gj+TB0/PrTPaLNt+nQZx9ChctymjTjwNm3qXTfHHD7MvGaN9/kvv9QvcuqUCLFJk0JzgxMmMDdurB9nZTGnpDBnZobghnxTUIQWyb3kH0qUKMHXPBw8Dhw4gLp168rByy8DO71TkwAAX0sGwghULMgpuCZNxDzIBzt27MDLL7+M1U5vx3r16mHp0qWoXLkyUlNTUapUKVy8eBGxsbE4fPgwiAglS5ZESkqKV1/a+Xnz5mHixIlYunQpLl68iBYtWmDTpk2YOXMm0tPT8eabb8JutyM1NRV///03hg8fjj/++AOAJKXMTmJJt+9Rka/Zt09SwzPrjrypqTLltX8/kJAAnD4toZOOHRM/qKwsmZGq5+mYkgN279bN1jt21K27PalWTQLVAvLv27ix7z5btJBZuaFDJR29X3btEsfcZ591P3/6NPD77/r8JbPEVHrpJaB5c5meszK9F4j16yUhl5H4eLEY0RzDrtMzmIhSmTnfx4MqPLEHAQCE3MhM0rRpU8THx+Ps2bNISEhAmTJlUK1aNWRlZeGNN97AmjVrEBYWhjNnzuDChQu4+eabA/a5bt069OrVC+Hh4ahYsSLatm2LLVu2oEWLFnjqqaeQlZWFrl27okmTJqhVqxaOHTuG//znP+jcuTM6GAOvKfItf/4p6ynBBEmdOVMceRs08C5LTxehVb++fu6eeySqQyh4/nlgwgTZ1wSKMQjukiXGFEHudOwIaLlRA/lmbdkCyWdy333AwL3uN+SJM9WPl9B6+GF3G/XXX5eOV670nY/EHw0b6tZ/48cDL74o+5qTFwBMmybCsnz54PtXuCh4QsuPRuTYtxMc5kCRuneG/LKPP/445s6di/Pnz7uyBf/4449ISEjAtm3bEBERgRo1apimJDHDlwbcpk0brFmzBosWLcKTTz6JYcOGoV+/fti1axeWLVuGCRMmYM6cOZg8eXLI7k2RN2jJ/ny9iO/dK0KBWdJrFC0K9OnjO3JEWpq3G1CoBBYgQV9vu02UFW0SQTNm8ITZXYDddluQCsecOfK5Zo1/oaWRleXu4+SZ3XHMmCAubsKkSSKgqlQRr+j27UV9NdKvn3e7QBF1FV4UntiDgEwNOnJHFe/Zsydmz56NuXPn4nFngLTExERUqFABERERWLlyJU4anQoD0KZNG/z000+w2+1ISEjAmjVr0LJlS5w8eRIVKlTA008/jUGDBmH79u24ePEiHA4HHnvsMYwcORLbtfzfihuCFSuAI0eCa+PvAb5+vUyhNWwItGkjVm0NG+rx9YwBFIycOJF9az5Pf6XKlYE33tCPNUWmSxf5HDhQPj1DI40YIc91QPyiNAKl5vCJL9UNAL75Rt+/dk00q/Hjs3ede+4Bunc3L1u+XOJNMYsmVbSoCFItBtWWLZIHxZNLl4LwSFa4yOtFtWC3nBhi2A7tZtvuLZbqZocGDRrwvffe6zpOSEjg2NhYbtasGQ8aNIjvuOMOPn78ODNn3xBj6tSpXL9+fW7SpAnfc889fOzYMd65cyc3bdqUGzduzI0bN+bFixdna/zKECN3yI7RQHKy73a+1vfXrAnOHiCYrUMHff/o0eDuzV+dv/6SsmPHgvt++JlnpOHXX3uXnT3L/NhjYsGhXXzbNn1/1izmihX147p1A38BCQnS9y+/MP/4o36+UiXmpKQgB583oIAYYuT5AILdciS0Du9l+44t7LBqRlXIUEIrdwhGaC1eLA9wzaEVYB4xgnniRO/+PLf+/QM/e822m27yXz5+PPMtt8j+W2+5j7dDB+ZHHvF/TxUqML/xRlBfWWB8Ca0zZ5hfecX7JjxzlRg3rS9/mydz5jC/+WaIbyp3KShCq+CtafkjPAzkAMQaw8+0gkKRRzz0kEQcM6Z5HzVKPqOj9YCyZkyblr1rRkX5L+/USbcrePll9zJ/iRQ1LlzI3rj8ws75U+P04PHjvuMueeYq0XjqKYn/N8kjVvdNNwEXL/q+fvfuvqcLFblK4VrTCg8HHACzyqmluLGIjwd+/ln2HQ5g8WLvOn36AM2aBdfvPff4LtMCxBojr2sY1Yw6dcROISYGKFcuuOsHRWKie6BCz8GYoUW4OXjQrxGWF0RiyfL99+ZBauPjxewdUJHVbzAKjNBiXz9qI+Hhol/ZswLVLHRY+v4UQWM1aljXrsATT+jHI0Zk73ovvQSUKqUfF3HOpWgGEhqjRgFvvy37qaliPV6nju9+hw3LfhBby7RqZW7f/+GHon5mZsoxM/Dtt7KvWZ/UrWtuZNG/v/e5Dh3EetDM6rBlS/kkErV23DhJ9KW4YSgQQisqKgqXLl0K/OANl/9gtimhZYSZcenSJUQFmidSBE2WyU8tJUWy3moCLTk5dM/F2FhRWHr0cD9fvrwYtgHiijR8uG7FB4iF48KFoRmDZZjFJ8puF3t5zexR06wWLZKskO++K+fPnQO6dRP7fo29e70tCMPDgc8/B5o2FRVRs+LTghG2aQNUqODepk4dMcNcu1akuMbQoSIQFTcMBWJNq0qVKoiLi0NCQoLfeo6Uqwi7lAjHIUZYURWY1khUVBSqVMm9dGaFjcWL5UXe+HzVePNNUQqyssR0fP780F23enX51NwBted5ZKQIKeN7XUSEnNOmCUtcz1gJx44BP/0kdvPjxgGvvqqXnTola1Oeauq//iXS1ciUKe7HRJL2GNAX4latEi0tOlrs7LUQIUbMpiUVNyZ5bQkS7GZmPWiVlLmfMAN8dfHYbPehUDBLgNaDB2V/7VqxhF6xQi/X1IUhQ/T9TZvE8rpLF3fDNH/ZKWJifJcNGcLcurX7uTNn5PrLl8uxZga/eXPge7p0Se8nJGRmMg8eLDlLPDEOevBg9+NvvvF904G2558P0eALHrBgPQigI4BDkEDmw/3Uexxi0dbccG6Es90hAA8GulZ2tzwXQsFuORFaqX/OYAb4yszXs92HQsHs/nD3tIx2OLL/zDVuv//OXK+eedm8eXKt2Fj383Z79u8pPd39PrJNpUoSlXzxYr3D9eul7No1EWbGQZcr535sFhnXuHXqxHzhgrwFvP22fn7nTgk+qzAlkNACEA7gKIBaACIB7AJQz6ReNIA1kGzzzZ3n6jnrFwVQ09lPuL/rZXcrEGtaVgkrXREA4Lh6JUBNhcI3xizAl0wywGVk5PwaVasCnTuLNbYR7Qn96KNyrK2ZNW4sEYE8U8UHQ2Rk9tu6ce6cTNutXauf27hR5iNLlPCOhuv5Je7YITGsfv/dvP9Jk2RNqmVL4L335Etgln6LFIgVj7yiJYAjzHyMmTMBzAbwiEm9kQDGADDGpHsEwGxmzmDm4xCNq2VuDLJwCa0yzkC1iUpoKbKPFhMQcLf4A4DNm327BFlBy6auJTJ4+GFngFiYRyzSlm++/DL4UFGeEInloWb3YIlffhEjhscfl0CDbFg00xzMAGDIEH2wmim5P3buFKc1T5jdLUgAJaisU4SIthq2ZzzKbwFw2nAc5zzngoiaAqjKzJ5vFAHbhopC9dcOL+v8DhNz23ZXkd9hBqZOBXr39o6fFxEhL/flywNHj7qX3XVXzq47caK4Dhmf95r2ZOZOpMmBbMfu8yAx0UKl1FQJNtixo3wmJupfhEm6Hb/06iXGEb//LoYTjz0m58uUESl6990SbHHgQEmZrMgJNmZu7qfcLOKC6y2EiMIAfApgQLBtQ0nh0rSiY8AEUFJy4MqKQs2IERIsQdM6Vq7UM09UriyfCQlirR0qevQQpYFZAoVr1KwpgtLTUA7Qpwd9RVPPETYbMHu2rvY98ojMIc6eLbmmevf2lnJm86X+qFtXLAdXrZI5z+hoOa95WmupPUaMkMjpitwkDkBVw3EVAGcNx9EAGgBYRUQnAMQCWEBEzS20DR25sVCWm1tODDGYmbNKEl/u2yBHfSgKBmfOMBuSSbuhrR716+duN3D1avAGFZ5b587e58Zm06C1Zk1pf/hw9r8HnyxapA/Qbtf377wz+JvW0hB7blOmuF8zPt49em5mJvP27blwc4UPBDbEKALgGMSQQjPEqO+n/irohhj14W6IcQzKECM02EuGg5KCnMJQFEjat5dIFGYOwEaMa0VmU3RG/u//9H1nWjWvJZhp0yRFSMWK+jmjm1IwaNODxlRROWLWLAmVcfGi+9znpk36vpXUN56Zs8eMkdiAx49LKg8td0lLj7X68uVFtdSIiBAnYUWuw8w2AC8AWAbgAIA5zLyPiN4noi4B2u4DMAfAfgBLATzPuRUvLzckYW5uOdW0rtWJ4qvtKuaoD0X+ZeVK5r17ZV972b9yRS8/cED8rYyaVjApP44e1ffff18+ly6VvjX3o8xM/XrVqzMPG5b9+5k8WfpMS8tmBw6H7nDG7PvGvv8+OM1KS98xYACzM62OG5cvi0m84rqBAhLlneRe8g8lSpTga9ocezZIaV4G7HAgeruVFWdFQUOzwGMWAwdmCW+kaUOeFnr9+ok2ppmY+6NPH2DGDL2PQ4fMQ+ndEFy4IAYVd90li3MjRohZ5H33BdfP99/rJo+lS0uAwuXLgQcekC/XX5JGxXWFiFKZ+XrGPckVCt/0YOniCL8aAkcaRb4hK0uMGHxZxn3+ucx+ffKJd9kPP1ibDQO8rQxvKIF19qxEzd22TSTrzTdLqCQt9NmoUcELrN27xVpFY+hQ+WzUSD6VwFLkAoXK5B0AuExJFEk6n9fDUFxHRo+WZRpP83RtkmHcONl88cEHIpCGDAGWLBEXIo2oKD3OnxZnsH59icl6QzFsmETEDUVU3DZtJLhsw4Zy3LOnWBS++Sbwwgve61kKRQgpdJoWly2NIokOdydIRYFgzx7gr7+8z591Gt6eO6efs+KIa0zVkZEBfPSRBGsw/nTS0nQfqVdekc+9e4Gvvgpu7CHn55+B6dOB22+XedDTpwO30dCsTeLidM9mQILbFi0qmtr77+vnZ8yQqUYiJbAUuU6hE1ooVxZhNsCe5CcrqeKGJSkJmDnTvKxRI/Okh1p2XWN4JV99GPGVBBcA3npL16xGjZJneaVKgfu8LsTHS6iOfv2Av/8WKbtuXeB2c+aI2njypKQFueUWoEEDCR2/cKHktUpPlxhTRsLDc8lRTKHwphAKrfIAANuF43k8EEV2+M9/xODBqAD448cfxcoa0HMIAsA77wRuq+UXBCRMkpGRI3U/2hdflGd5ni7haOrfokXutvSe5UZ+/x1YuhRo3VqOy5YV6RsdrYdQiooCTpwA/vnPXBm2QhEshU5oUTlJ/uZIOJnHI1GYsXy599qTEU1QGKf6PFm1Cti/X+wEjJF/tCAL/jCuV2nTfYB7hIo8x2aT5IkTJ8rxo4+KieO5c4GFi+YfBUhE3gcf1PNOaWtUCsUNTKETWmHlJQaPPT4uj0eiAMSy77vv9HBIDz7o3+ouJkY+/cXIa9dOjCGCibaumaobr92tm74fMufdQHz9tVj4Gfn+e0kPn5wsC2bVqkmA2mefFYvAX38FFiywZpc/ebJM+xl5/HHRxDyz+SoUNyCFT2hVrAYA4PgzeTwSBQB88QXw9NMSnFbDM2EtIDYBCxfq6/w7doglHyBTgGZJqwNFujDSp49c97oszRw75h5h4tdfxVCCWUJlNG8u1ng9eoiV3r/+JYFkS5USbcioZhqtATdulM8ePeRzyBBg61bv6+/b519VVShuZPLauznYLacRMVLPbmcGOPHdXjnqRxEaXnlFAid88AGzzaYHVDBy8aJ+fsQI98ALY8f6DsrQtq3vMs/NyOOPM7dpI/tm5aYMGSLpi61Qtqx0mpUlQQMB5o4dmY8csTbY55/3Xx4Xxzx3rkS7YGZetYq5SBHm48etjU9RIIGKiJE35DQiRlbmJYSXvAkpg9qj1Nd/Bm6gyFWef17Mw1u2FH8qLZD3unVAq1aybzRwKFJEj7eXXSIj3Y0yAN8eEMYIGn6xWvHQIeCOO2T/2WdlAc5KfimNoUPFqWz3bpky7NpVLEbGj5fw89WqAS1aWO9PUWgoKBExCp1zcZGI0sgoA1BCkCkUFCFl/nyJIKQ55m7e7J554p575Pl/+bJ7u5wKLECWhn76SQRmdDTQvbvvugMHei8xeeEpqOLixBHs3ntFOmopgTdu1FNtALJ+FQy9ekm4JUDs+xs1krQhKvKEohBR6IQWUTiyyoUjLF5lL84rsrLEyKFePf8BvLPiRgxyAAAgAElEQVSyJDFuTjl0SGILlighYZkiI4Enn5QtEJMnW7iAp9rWtKlESY+PF6OHTp3ESMJTAlshPV20sQcfNC9XAktRyCh0hhgAYCtbFGEJSXk9jHyN3S4PdCuaz9Gj4l91+rS003ye9u/XNS0znntOjDSygzEOYESERK1gtiaovOjTRzduMMNzuvqi03F93TqRvAsWAAMGABMm+L9OixbAmTPApElyfOaM3IgvgaVQFEbyelEt2C2nhhjMzAldK3LmTZE57qcwM3GirPk3aaKv9/siKkrqVqvG/N131mwNsrNVqaLv//KLvp+SksObDWSN0bevXqduXesD7t1b369cWc+R4nDkINeIQmEOCoghRqGbHgQArlAWRa5ckNf+8PC8Hk6+YcUKoEYNicmnzXTt3Cmm5xcuiEISGQmcOiXuRFpQBU2bOnVKIgXlFk2bynISIEHMAaBkSZkWDCnJyXKjYWHAnXfKzWoEMqqoXh2oXVvmKW+5RbaWLcVXSoNIIlEoFAovCuX0IFeoALJDD6+gsMQDDwC33iqZd42yfvBgyVDxwQdyHBsrwRbmzRMDNyPLl5v3/a9/ZW9MH3+s7xv9sjT/2bFjLXbkcHhP85mRmCidN2wogscosN5917v+okX6fny8hET68099gGPGuAsshULhl1wTWkRUlYhWEtEBItpHRC+Z1CEiGk9ER4hoNxHdmVvjcbvuzc6oGGdU/EFfxMeLz6sZAwYA//uffqwFEP/gA/GZ1fxWH3/cPYisv1T1p04FP8aHHgJee00Uld693YVWqVIy7zZ4sMXO3npL1LLUVN91tBtPTgYOH/aWtN26SXoOI7Vr6/vly1scjEKh8EVualo2AEOZuS6AWADPE1E9jzqdANzq3J4BEKQNcPYIq3WrDPBvi9n9CiGawduWLWLyrQVb0Dh40LsNs2hZvtBCMJnhS8nxDJ/03HNinwDoOQc3bZKoGEajkJIlfV/LlPHj5dOfjf20af5DJTVoICk7UlOB994TR7PbbpOQ8lYzSSoUCr/kmtBi5nPMvN25nwzgAACPoGd4BMAPznXCjQBKE1GuJ3iguk0AAI59OwPULHwcPixrV1rQ2pYtJaqQ0b0IkKzqwXLihO8ybd0rNlaWfbR1KG1tSoNIfGiZ3f26AIlapPVRxNdq7d690smuXe7nNamphY9nluCFr75q3o9n4q6NG2WNKyxMYkG9/bZYDxKJf5U/236FQmGZ67KmRUQ1ADQFsMmj6BYAxux0cfAWbCEn8qY6yLgJ5upCIee222TtKpD7j7+AtcHSpYsutL75RoSbFn9w5Ej3uv7G1aWLyJoNG/xcbO5c+fTlAPbooxI9NyxMjCE+/9y7znPPAXffLREtNO66y89FFQpFqMh1oUVEJQHMA/AyM3s6R5k9grzi4BDRM0S0lYi22kIQEiEy8makVgPC/z6R474UOWfSJF1oaQFr2fkr6NZNpiqrSZxja35Wu3f7ztSrhX6PjJSwGHfe6R2Zwuwi998vn8uW6f5Wn30mfWRH7VQoFNkiV4UWEUVABNaPzGz2ahsHwJgGtQqAs56VmHkSMzdn5uZFfM77WCciohxSqxOKHD1vIahc4cTXc3j4cOC++3LW91tvuR+XKCGzaYBErgAkvJ5WtnixJNNllunKgDRurEs5QKz1tmwRU0YtesWFC0DPnhIu/rnn/Pf31FNi15+ZCXTooJ+PjJQMwf4W6xQKRUjJTetBAvA9gAPM/ImPagsA9HNaEcYCSGTmXM+ZQBSGjFoxCEvJ1Ff1FVixInCdtDQxezejeHHvc7Nn6/uaJ+3Ike7Ti8WLS2Z4Zl3Tev55OQ7KjS4x0X3+UBNQ998v0q5SJV3T+uIL7/ZHjgCffqq3+ekn2X/ySVkku25JtRQKhS9y07m4FYAnAewhIs3i4Q0A1QCAmScCWAzgIQBHAKQCGGjST65gq1MRwFVxBtVe7wsg586JdV3Xrv7r/fKLpGwKRO/ewMqV5mU33yypojypUQN45BH3c5pJekjxzBFljOWkEecj+eeKFWKe/vLLsqhXq5ZI0PbtgZtuCvFAFQpFdsk1ocXM62C+ZmWswwCez60x+MN+W3UAh8QY44EH8mIIIWffPrHYbt1aP9ehgxjMzZ/vLTg0rlwJLLAWL5a1JUA3sANEGenRQ4wgzp71FlrMwPFQu8OtWiUqmPFGAdGUAvHbb+bnjeaR9evr+0pgKRQ3FIUyIgYAFKlyO2wlAd6/P6+HEjIaNADatHG3K9BM1z01rcRE8W3KytID2PrDOE1nzO77xBMimH77zXytK1eWDNu1kxsdN06PatKvH/Dww9nrr0sX87lNhaKQQUQdieiQM+DDcJPywUS0h4h2EtE6zfeWiGoQUZrz/E4imphbYyyUsQcBoFjxOrhWDYg+sNu/OpgP0ewKOnRw91c6dUqUlHr19DyBu3dLJKFAGKOx+7KFGT0aGDVKrMU17rknqKEHx7Bh4hT8+efA9OnBtS1bVnckVgJLoQARhQOYAOABiJHcFiJawMzGN/uZzqUdEFEXAJ8A6OgsO8rMTXJ7nIVW0ypWrDZSqwE4UDB9tZ57TsLjGQVM9epA//7uiW21LBhGXn/d+5yxjSaUevXyrme0g2AGqlb1rhNSTp/2H6UCEMs/Iy1ayFyqZsZotvalUBQ+WgI4wszHmDkTwGxIAAgXHm5LJWDiopTbFFqhFRUlQiss/rIs6hRA0tICW995mraPGycakyfGGIKa0LLbcza+oHA4gJQU6xFwly7V9zt2BBISJEIFALz0kliNjBgB9O1rfsMKRcGjiObv6tye8Si3FOyBiJ4noqMAxgB40VBUk4h2ENFqImrt2S5UFNrpwaioGkit7jw4eNA7TlE+wm6XgONmBJt5xUoaD61PLWqFJ/XqheDr3LpVpvw++0zUty5d3COm+6NfPzGu2bJFN3u/6SbZLl6UqUFApgWDnVZUKPIvNmZu7qfcUrAHZp4AYAIR9QbwFoD+AM4BqMbMl4ioGYD5RFTfJKBEjim0Qis8PAq2W28GcF7M3m9gobVjhzx7fUUKmjBBlAczLlwI7lpW/GQDCa19+4K7pildu4oP3ZkzkuPECjNmyJylpgo2N/n/LFcuBINTKAokloI9GJgNZ5BzZs4AkOHc3+bUxG4DsDXUgyy004MAgBq3wRFBgRP35TF33uk/evratcH152mCbtSutGnANm1EuSlVSo9WoXH33fJpDL2XY+x28aE66/wf0ZIg+hJYjRq5l02dKlkowwr3T1qhyAFbANxKRDWJKBJAT0gACBdEZAwt0BnAYef58k5DDhBRLUjmDhOvzZxTaDUtACgWXQdp1dejhGfE73yG0bLPChUrim/Vxo0SHmnRIuDee6VME1qrV/tur0VZDykdOuhJujIydFt9X3z4IfDPf+phNgJF+FUoFH5hZhsRvQBgGYBwAJOZeR8RvQ9gKzMvAPACEd0PIAvAFcjUIAC0AfA+EdkA2AEMZubL3lfJOYVbaBWrjav1bCj+vw2g5GQgOjqvh5QttMhEVvj1V/GzMoZXAiRV1JAhYmF4XZg0SRy7atcWpzFjVknPtB9mGHOWKIGlUIQEZl4MiVRkPPe2Yd90IYKZ50HizOY6hXoupXjxeohvD1BKiu888HmMFY0mGKHly9CiXz+xUdBm5XKVpCTg3/+WwLabNwMff+xebpSoAwaIL5aW9bdPH2DyZKBZs+swUIVCcaNRqDWtkiUbIqkuwBHhoC1brAXfu86YCaRz54DvvxfjjAYNgDVrAvfTrp3vmIG5ziFnuKxOnfTYfoAkXjSzLtGcx+bO1f8mHToAd9whkXRvYKMZhUKRuxRqoRUVVRMUVRwZt5dElDGg3g2EZrGtsXChxAGcGGSQFM3JOATpyILnjjvkc80aiTHlmb/KjAoVgM6d9ePbb1dpZBQKReGeHiQKQ4kS9ZHUNEoeqKdO5fWQvDAKLWax6LMisPr3d3/GDx0qn3feGdrxBUWbNv7LZ8zQ9y9cuE5zlQqFIj9RqDUtAChRogFOPnIMFWbYxRrhv//N6yEBEIEzfbpuXg7o6Z2sMHWq+/GDD15HRWX3brH+s9uDc9qqXRt45x3/9v0KhaJQo4RWiYY4X24KuE5t0KxZEngvMjKvh4WePYE5c9zTiZjF+gvE3XcDt3gFYslFOnaUlPT+aNRIBBsg8f8GDJAw8XfdpQSWQqHwC3E+WycoUaIEX7t2LWT9Xb78B3bv7oC7/hiAYh9NFUu1//wnZP0Hw5kzwPbtYmegGcvddZckcfRHqVJikGckT/6sdrvvEPAatWpJgq/w8Bvi5UChKCwQUSozWwjUdmNTqNe0ACA6WhZ5Ev5dF6hWLfjwEiHg4EFx5m3dWtasjEFsrWR4NwaBuP/+65DTcuhQ2W67TSLspqRIOnszgRURIUYVgJgvHj0qjmJKYCkUimxQ6KcHIyLKISqqJpKTt0ryp59/Bq6zo3Hduu7HFy8axxe4vVGr+uOP0IwJmzaJ6fl33wGzZskU3pYtEmbpk0/0esOGSV4qX9aXcXEitFJTVd4qhUIBACCiBsy8NzttC72mBQDR0c2RlLRZPGyzsrytGK4z8fH6vhXfKodDIlm88EIIB9G+vTjxnjolDr1ZWUCTJsBDD3nXHTVK3/d0GtO0LCWwFAqFzkQi2kxEzxFR6WAaKqEFoFSpu5GRcRLpbesDdeoENiQIAcnJwMyZ5mUjRgRuX6uWvu9wACdOAF98EZKhCZpXczAmi9OmyRzn5csSdv46fI8KhSL/wcz3AOgDiSq/lYhmEpGlhY1CPz0IAKVLS76yxMS1iHrgAXF+PXbMXTKEmMGDRWiZKSD793uf8+TjjyXIbfnyuWB0MX26nuHRLI2xGV9+KZoqAJQpI3mwFAqFwgfMfJiI3oKkLxkPoCkREYA3mPkXX+2UpgWgRInGCA8vicTEtZLBEDCfBgshJ0/KZ7du1tskJenDKlpUzxKfY6GVnKzPSU6dqgufQMyZIybqQ4dKeCWFQqGwABE1IqJPARwA0B7Aw8xc17n/qb+2SmgBCAsrglKl7hah9eSTctJmy1W78WADky9eLLYhmgIUHq5raZ7xZi3Rv78MIiVFLEEqVpT7HTjQWvs//wS6dwc2bBALQoVCobDOlwC2A2jMzM8z83YAYOazkGzIPlFCy0lMTGtcu7YXWcXtwAcfiGl2tqSBOUuW6NqVFcaMcT9u3Fg+tdiBRYqI4GLOhltZairwww+yP3++OIgB/hMoVqsmgkqjWLEgL6pQKBQCM7dh5unMnGZSNt1fWyW0nOjrWuv1qa4335S1rRDw0EMSCELDnxLXpYtYkhvrVq4s+0OGyGfTpjkYzHTDb0LTLM345hvglVdEzTt5UiwKH3wwBxdWKBQKyYBMRHOJaD8RHdM2K22V0HISHd0SRBEyRVi6tIQZCg8H/u//QnaNpCSJCesZvcITo8Dy5KGHRIhpETNcrFsn0307d7pf8LJH8tB33xUrEF80bAg8/LDs33GH+GR16qSXT54s5o1mKUUUCoXCGlMAfA3ABqAdgB8A+NWwNJT1oJPw8GKIjm6JK1ecU2ANGwJPPCHaxrvvmkiJwCxYADRvrqewB0Sxefpp38l527UTH+eg+cVpbLNwoR6ZomFD+bx0ScLFGwfiya+/ilXIiBFitt6ggXu0Xo3KlYGPPsrGABUKhcJFMWb+k4iImU8CeJeI1gJ4J1BDpWkZKFu2I1JStiEz84KceOEFsXyoUAH4/feg+rLZJNht+/bA0qXuZd9+678dUlMDX2DOHFl38+Ttt0VYtWqlnytXzl1g3Xsv8Nxzsj9jBnD8ONC1q6hwvXoBVaqIYAoUR1ChUCiyRzoRhQE4TEQvEFE3ABWsNLQktIjoJSIqRcL3RLSdiDrkZMQ3IuXKiT355ctOp9jYWN1PaeBA4KuvxJPXAtu3y+ehQ8FZz7/adgtQooTvsEiAhMno0UMcobXFMc9FMn9zkCtWABMmSJs+fYAaNawPUKFQKHLOywCKA3gRQDMAfQH0t9LQqqb1FDMnAegAoDyAgQBGBz/OG5uSJZsgMvJmXLq0WD85erSoTBcvioGGxZTBwS75fPGFM8nj5alywl9o90OH9P1Ro0QjtJqSeMkSWatTKBSKPICIwgE8wcwpzBzHzAOZ+TFm3milvdX5H82r6CEAU5h5l9NzuUBBFIayZTvi4sX5cDhsCAtzfj0vvST5ngARXE895TerrjEBrxUeeMAQN1DTmMy+3j//BJYvF41P4803zTt99llx+t2zR9r06SNhlXI9BLxCoVD4hpntRNTMuZ4VtDOsVaG1jYiWA6gJYAQRRQOwNk+Wzyhb9iGcPz8VSUnrUbq0Mz18u3bAjz/Kgx8QC4vu3U0Fy44d/q3IzXjtNcOBQWjdcYfTFiIhQdbW7r/ff0eDB4sm+MYbwIcfyrnatWW9CnBf51IoFIq8YweA34joZwCuBIn+wjdpWJ0eHARgOIAWzJwKIAIyRVjgKFu2I4iK4uLFX90LevcGRo6U/R49xCx8wQKJgm4gO/rn/fdDhNIrr0jkWwA4dw4Hwurj+7LDxBDE0/LvjjskCdelS3o8p6FDRehpAkuhUChuTMoCuARnCCfn9k8rDS1lLiaiVgB2MvM1IuoL4E4AnztNFa8roc5cbMaePV2QkrILsbEn4DULes89XvbqvGAhfrjQAT1aHMex9MqoH2stF1fbpkkoX7sUfr5vIvD998DWrdYHabfrESxSU4HTp4Hbb7feXqFQFCoKW+birwGkElFjAK8BOAlxBiuQlC//GDIyTiEpaYN3oTb3p2k3ABZ3+RoDno7EW00Wwhbrewru527uuUhW7YjBz11/lPUnqwJr4EDgH/9wD7lUvLgSWAqFIt9ARFOIaLLnZqWtVaFlcy6YPQLRsD4HcP1S+15nbrrpUYSFFcf581O9C595RtaY0tNdDldXUAYAcA6VYIdvy7zIX2ejGTyEU9++1gf27bcSkWL9euttFAqFwiJE1JGIDhHRESIablI+mIj2ENFOIlpHRPUMZSOc7Q4RUaB4b78DWOTc/gRQCkCKlTFaFVrJRDQCwJMAFjlNFi0kgs+fFCkSjfLluyM+fjbsdg9HXyLgpptk/1//kmSJg5+VIjBsfmxbIpCFrWhhfSCDBwP//rdYDXbpYj1liEKhUASJ87k+AUAnAPUA9DIKJSczmbkhMzcBMAbAJ8629QD0BFAfQEcAXzn7M4WZ5xm2HwE8AaCBlXFaFVo9AGRA/LXOA7gFwFh/DZzqXjwR7fVRHkNEC4loFxHtI6IbyrCjUqWBsNuTkZAQwJglMhJ8t3NKsE1b2Jp4C6VG2AUASEFJ4JlnUL3oObyKccB990kFYzqQEydkfWrKFDFtnzhRwmr89hsQGRmCO1MoFApTWgI4wszHmDkTwGzI7JoLp7+uRgkAmlHEIwBmM3MGMx8HcMTZn1VuBVDNSkVLQsspqH4EEENE/wSQzsyB1rSmQiSuL54HsJ+ZGwO4F8D/EdEN81SOiWmNqKhaOH9+iuU2VK0qZt7zldf5b6aKT1czbAO++QYn0ithLL8qkSmYZcrv8mVxEK5eXcIoDRiQPVNEhUKhMKcIEW01bM94lN8C4LThOM55zg0iep6IjkI0rReDaWvoI5mIkrQNwEIAltKkW/LTIqInIJrVKoij8RdENIyZ5/pqw8xriKiGn24ZQLTTSbkkgMuQiL83BERhuPnm/jhx4h2kpZ1AsWI1fNbVDDBTUrwdi1u2BGL73w6uuxk47ycFfZkyOR+0QqFQ+MbGzM39lJu9JXuZlzPzBAATiKg3JGFjf6ttDX1k2ybC6vTgmxAfrf7M3A+i9v03uxd18iWAugDOAtgD4CVmNnVYJqJntLcDm9VwRSHg5pvlb3HhwjRL9T3j3L72miEaU8uWsi6lUCgUNyZxAKoajqtAns++mA2ga3baElE3IooxHJcmoq6+6huxKrTCmDnecHwpiLa+eBDATgCVATQB8CURlTKryMyTmLk5Mzcvch0jj0dFVUfp0u1x7tz3cDgyA9ZPT78Og1IoFIrcYQuAW4mopnOppieABcYKRHSr4bAzgMPO/QUAehJRUSKqCVmj2uznWu8wc6J2wMxXYSEtCWBd8CwlomVENICIBkDMFBcHaBOIgQB+YeEIgOMA7shhnyGnatWhyMg4jfPnfS/haYHf16xxPx98VC2FQqHIG5jZBuAFAMsAHAAwh5n3EdH7RKRNE73gNJzbCWAInJHZmXkfgDkA9gNYCuB5Zrb7uZyZ7LGkkViqxMzDiOgxAK0gc5eTmPnXAM0CcQrAfQDWElFFALcDCE1u+xBStmxHREe3wKlTo1Gp0lOQFDDuZGWZt1VCS6FQ5CeYeTE8FBJmftuw/5Kfth8CsBpDbisRfQIxsWcA/wGwzUpDy3NtzDwPwDyr9YloFsQq8CYiioOofhHOviYCGAlgKhHtgQjC15n5otX+rxdEhCpVhuDAgV64fHkZypXr5FUn08fMoRJaCoVCYcp/IHYRPzmPl0OMOgLiV2gRUTLMLUAIADOz6RoUpLCXv76Z+SwkP9cNT/nyj+LIkYo4efJDZ0Bdd0MZX0LLYr5IhUKhKFQw8zVIEPag8bumxczRzFzKZIv2J7AKGmFhkahZ830kJf2Fy5e9l/KUpqVQKBTWIaI/iKi04bgMES2z0janFoCFhptvHoioqBo4fPgFxMdnYe5cieD08svAcB/vC0poKRQKhSk3OS0GAQDMfAVABSsNldCySFhYBOrUGY/09BPo3v0iuncHnn4a+Pxz322U0FIoFApTHETkCtvkDERh6YmphFYQlCvXGcWK1cGJE/KCsH27//p09ycYtnzYdRiZQqFQ5CveBLCOiKYT0XQAqwGMsNLQUhLIG4nrkQTSH+fPT0OlSv0D1jt1Cqg2WQw2+J389R0rFIqCx42WBJKIKgB4BhJkIgpAPDOv8d8qCJN3hRAR4VtgMQPVqkmQdmU5qFAoFOYQ0b8AvAQJ97QTQCyADQDaB2qrpgeDxO7PxxvAyJHyWcHSkqJCoVAUSl4C0ALASWZuB6ApgAQrDZWmFSSe8XqbNTuD4sVvQcWKcty/v2xmZNgywGBEFYnK3UEqFArFjU06M6cTEYioKDMfJKLbrTRUQitIPH2y7PajWLz4EkqWbOR2fs6+OV5tK4yrgOSMZDjeUXOHCoWiUBPn9NOaD+APIroC/xHlXSihFSSeQosoAvv2PY4WLfYhLCzCdf6Po394tU3KSPI6p1AoFIUNZu7m3H2XiFYCiIEE2g2IWtMKApsNmDTJ/VyxYrciLe0wDh4cCGZGalYq2kxpgz3xe4Luf9jyYfh0w6chGq1CoVDc+DDzamZewMyB8z9BaVpB8emnwP/9n/u5YsVuQo0a7+PEibdRpsz92HXtZqw9tTZb/Y/bMA4A8Mo/XsnpUBUKhaJAojQtizADY8fqx48+Kp+VKgHVq7+BmJjWOHRoEC4nBvA4VigUCkW2UULLIgsXAgkGg8wHHpDP//wHIApHw4aLUbToLTh6clzeDFChUCgKAUpoWeTyZffjunVF+2rZUo6LFCmJOrf/iKTMtOs+tnRbOjJsGZbqJmUkIb9FQVEoFAoNJbSySUSE97n2Pz2HcYfSr/tYin1YDDU/rxmw3vErxxEzOgYTtky4DqNSKBSK0KOElkVmzXI/joz0rrM3fu/1GYwJ51LOBaxz5PIRAMBvh37L7eEoFApFrqCElgUOHACWL3c/55G82C8OhyVLThe7zu9C6ymtkZqValr+7qp3MXL1yID9jFs/DsNXZCs5aEg5nXgad313FxKuWYrSolDkOqtPrMaDMx6E3WFHhi0D7ae1x9azWy21XXBoAR6f83gujxCYsmMKnv392Vy/Tn5DCS0LpJrIjpQU6+337+8N5gBBCw28vOxlrDu1DpviNpmWv7f6Pby96u2A/Qz7Yxg+/utjy9fNLT7d+Ck2n9mM6bun5/VQFAoAQI+5PbD86HLEX4vHzvM7sfLESjy7yJqAeGT2I5h3YF4ujxB4asFTmLhtYq5fJ7+hhFYA0tOBH37wPl+3rvU+Ll6ch02bbrVcP5zCAQA2h81vvSWHl2DBoQXWB2Jg94XdWH96fbbaBotm+EEIQj1V3BDsubAHf536C3aHHZN3TA74m9wYtxG7L+wO2O+2s9ssaza++P3v33E2WY/8w8z4esvX2HZ2W1D9ZNplJiQy3GTOH3JPO8/vxP6E/VhzUs+c4WAVji0vUM7FAXjvPWD8eO/zwURxr1p1GE6fHhu4opMiYfJnCfSAeGjmQ9YH4UHjiY0BXN9cXxTMnKrihqDRRImpOeWRKRi0YBAupl7Ea61e81n/H9//A0Dg31Xzb5tbqucLZsbDsx5G9ZjqOPHyCQDAmeQzeG7xc6hUshLODrUUxg5EhCxHFgDfQku7J0/sDjvCwnP/vZ+Z1f+OAaVpBSA+Pud91Kr1MapWfdV1nJDwq9/6mtCyBzGlGAhmRmJGYrbaJmckw+7wPRajGX1yRrLXGyjDt6Zlc9hwLfOaaz8l09q8a2pWqusNuaCRlJFk+n1n2bN8rnMa2/pzaUhM138DaVlpPr9Dz36SM5IBiNYBANcyryHLnuXWxorbRaj+bpfSLgEATiaeBCDa0uU08UuxYpSk/SYd7HDTtFIyUwK+LGpowk77Th3syJX4ohl2a+4shQUltAJgZtoeLESE2rV1TevQoaeQlGS+XgUA4WHWpgc98TddMWnbJHT/uXtQ/QHyYCs1uhSG/THMtPxM0hnEjI7BuPXjkJieiFKjS+G///uv6bjM3hYfnvUwSo4qCQDo92s/RI+KtjSuEh+V8PkGnJ9Jy0pDzOgYjPjTO/P4PVPuQYmPfCeevZByATGjYzBq3SjT8r3xe1H649L4YZfMdxf/qDjqTvCe5z6dePNHntAAACAASURBVBoxo2Pw2cbPXOdeXPoiAODXg/LCVXJUSTww/QG3djU+r+H/5iB/t9ZTWges549NcZtQfmx5t3OtJrdyzR5YQRPINofNJWwjwiIQPSoa/X7tZ6kPm8OG/Qn7Xd/pe6veQ8zoGFxJu2J5HFaw+iJXWFBCKwBmpu0jAxvu+aVIkTLYsaM1zp791rzc4vSgJ/60oeyauV9Jl3/AmXtmmpafSjwFAJh3YJ7r7XfmXvO6ZprW0iN6YOdZe2d5lftj+7mCFzLr+NXjAID5B+d7lW0+s9lv2zPJZwAAP+//2bRcW2tafHix69yxK8d8juGXg7/4vd7qk6vdjs+nnPdbXyPQfWSnfXbXx+wOu0t71V4Wrf4ObQ4b9sXvAwAs/Huhy9BI0/hChTYToRCU0AqAmab11ls567NZs60oXbo9/v77GRw+/CIcDnf13zU96EcImeFP09KmQ6zw6YZP8dofsm7x1ZavAADFIoq51Zm7fy56zu3ppj1pb69h5P6zMk4z/XbwN/SY28Pv9XMzYscvB34JeP3rycmrJxH7XSwupl4EoL8EVI2pilOJp3DXd3ehzZQ2WHsycBBm7XuLS4oDvUd48tcn3cq1lwZPjTfTnomOMzq6hMHodaMBAOtOrfO6hvbb9GTazmlux1N3Tg04Xn8sPrwYT/z8hNu5b7Z+gxeXvJgjA4hTiafQekpr1wvWt9u/Rf/5krXVc7rz2JVjaDW5lc++bA6b67c+d/9cl7DXpg2NpGWlof209lhyeAk6TO/g+ntP2TEF90y+B4npiTh59SToPUK9CfXc7r3ldy3x5p9v4oXFL2T7vq1CRB2J6BARHSEiL38ZIhpCRPuJaDcR/UlE1Q1ldiLa6dyyZyFmASW0AhCK6UHvPsuiUaNFqFLlFZw58wV27rwPmVn6WoNV60FPrK6BBRIKQ5YPwdj1Mp354doPAcAr23L3n7vjp30/uZ1zTQN6aFSuNS0idP2pq2mCTCOhXMvz5LE5jwW8/vVk7Pqx2HRmE2bvnQ0AuJp+FQAQUzQGH6/7GJvPbMbaU2vReWbngH1p37P2QJyxe4alMRy8eBDLji7DoAWDAABLjizxWTciLMJ0TWrAbwPcjgf+NtDStX3ReWZn/Lz/Z7drDV40GF9s/iJHQuvjdR9j3al1rj5GrRvlEjKeAvnDNR/6tbC1OWwu7cyImWa0/vR6rDyxEg/NfAh/HPsD323/znVPf53+C4cuHcJ/V8q0+oGLB9y05fhr8fho3UeYsGWCl2ANJUQUDmACgE4A6gHoRUT1PKrtANCcmRsBmAtgjKEsjZmbOLcuuTVOJbQC4DU9GHENM3bPCEobsDvsmLJjits5onDUqfMJ6tWbjaSkDXhzbmlXmfbPc+zKMbfpMyvX8YWv8RrbxCXF4fe/fzetF1UkCkcvH8WKYyt8X8MgnMyubRRmzOxzOilYDTMvSLelY9z6cabTa0Zm7Znld01C+060e9a+fyJye2AnZya79mfvne1a/N92dlvQJt6eaGs6RcOLBqwbRmFuD+VQmX1vituEned3ep1fc3KNl+C4cO2CpT6ZGVN3TnWNd9aeWX7bptskBFs4hcPBDvyw28TXxcC2s9tchilGrqRfwZBlQ/DEz0/g8TmPY97+eV4GNMuOLkOmPdP1N76YetGSH+PkHZMD1skBLQEcYeZjztxWswE8YqzAzCuZWbuZjQCq5OaAzFAm7yakpAC//Qb06eOtadV7ZQie/HUSqsVUQ5vqbSz19+XmL/HyspdNyypU6IEMuwPjVvd2nQtzPvw1B2KrZsH+NBTj9KBxP8OegeJhxQEA9069F0evHDVtTyDU+aKO3/H48scyE2YOdqD9tPZuxxo2hw1FEfgBmhMc7PCaxgyGP47+gWF/DMOuC7swvZv5w2bb2W3o/Utv9G3U12cdbQza/f+450cA8h2aTTMBQK95vfBo3Ucx74l5bqbj2RUgmlAtWiTwd57lyMK1LF1oTds5DQObWtOq/L2MxH4fC0DuwygINGMP42/OqsP8qhOrMPC3gdh2dhv+3fzf6P1Lb7/1tfXbyPBIzNg9I+BMR5fZ5srER2s/wsoTK13H8w7Mw+zHZrvVOXzpMFYe1+usOrHK77U0tFBs2aQIERkX/yYxszGt7S0AThuO4wDc5ae/QQCManmUs38bgNHM7L0wGwKU0DLADEybBgwZAly5AsTFAYcP6+V33glUaXoe+w/pi63MjOTMZJQqWspnv4HeDEuX/afb8cUEc0OGQBgfWkbTZk+MUwxpWWkoHiFCSzMfNiOQ2S2DfVoJmgmzLEeW2z+g8YEWzLSogx24lnkN0UWtWR1qJGUkoXRUadOyDFsG0mxpiAiTN5YSkd4We5pw1+45MT0RMVExrvJMe6br7x6XFIcMWwYc7PBaG9SmlxjsplmFUZhPoQUAJ66e8Dpn9XtjZtc0JKAbUFjRtDLtmW6a1v6E/X7r2xw2pGWlIbpotKnLRZY9y2u60cyQ4UzSmYBjM3Ly6knXfe1N2Ot2v77QplXTbGk5sgA0+9t4nkvKSMKyo8tcx4cvH0Yg+jTsg7EdrPt7mmBj5uZ+ys2cwUzfUImoL4DmANoaTldj5rNEVAvA/4hoDzObvwXnADU9aGDBAmDgQBFYADB8ODDd8IK8dq3ugKj9o435awxiRsfgXLJv35BAU4meD5twZO+NWXvwrz25FqU/dn8gG8dgfBhqUyIAUDKypM++yxcvb3rerF9fkS+Mwsxzbt44pkBrWsZrvrfqPZQaXSroh0yZj8v4LKs1vhbKfFwGJUeVdJnje6IZTERHRmP96fUo/XFpt6nVdtPaua1D1Z1QF8U/Ku7Vj1HTMt6D5/SgJ2a/KbP1DrN6P+37ye3+v9n2jdxLAMFfIkKEt1EAjNswDkcv+34u9Z/fH6VGywtduTHlvMofmP6A13dsdt9VPvU9C2Um0Gp8XgP//v3fAESL6fZTN5/tNYyCRVtfyg6aQYaR4X+62zQkZybj042fuo7NrEU9aV7Zn7wJCXEAqhqOqwDw8tImovsBvAmgCzO73maZ+azz8xiAVQCa5sYgldAy4C+eYHIyULw4XG/f2gNCWzDVzI3NCPQQ9hRalSu5W32lp5/y297zOmaLx8YpQePDzXhtM6HVrkY7AMCdle70e01jX17WgybOxZ5ahHEcgTQG4zW16TTNGiwUGEMD+SItS/KmZdmz8NepvwC4T/F4/g3MHmSAu9AyCgNCAKFl8gJsVt+KI682LehL89TQhFpCqnvg4x3nd/hso7lK+HI89jSbB9xfpKzgy5nYuA6oaVFWMbbNLnfd4m9mTahdpraXkZMvXrzrxZwOKRBbANxKRDWJKBJATwBuVoBE1BTANxCBFW84X4aIijr3bwLQCoB/NTybKKFlwMwnSyPcaSRk1LSOXj6KbedkEfynvT/5ahrUQxgAJm53X//YvLketu57Dv/4riWOXzF/+AG6pmW2tmF84/YlIMyEltaXcfrO2JfxvOaMaiXkjM1hc6vnOabE9ES0mtwKhy95T5sYha4vi0WzNl1ndw04LjNMtRqn0M10ZAaMXWfklaWvgN4jvLjkRSw5vMRlpelgh2tNRcOfwHGwwy0VTs+5PU3rGwWAL7cHrc4Pu35wWbWZof0+LqS4T3f7clo3OhFrmmkgftz9Y9Bas7//vbzEl5CpFlPNtR9bJdaykM7JGqwVmNkG4AUAywAcADCHmfcR0ftEpC3gjQVQEsDPHqbtdQFsJaJdAFZC1rSU0Mpt/AmtIs7VP5em5cjCB2s/cJWP2zDOZ9tA1nCBhFqRyGqYuetrbDyzBR+s8o6U4LoO+xZaRoxajvHa2r2Zjc1MozLuM7PL+snLEMP50Df24TmV5dnnwr8XYv3p9Xh39bs+xwToD+JAfmj7E/Zn28Ha7KGiCQjjmowVofXZJhHsX2z+wi12pIMdiEuKcx2HUZhf82ZmxstLdeOen/b9hDSbd9Zs49h9/S6MdZ5e+LTPa2pCK/6atdhmRj+vQ5cOWWrT99e+XsI7EP7+96zyz9v+GbhSkPj6PXSv1x19G/VF1zu64pMHPwn5dXMCMy9m5tuYuTYzf+g89zYzL3Du38/MFT1N25l5PTM3ZObGzs/vc2uMSmg5YQYm+7Em1TStiHD36UEreGpSnm/ugYRW4yarXcYaly/N9VlPeyiZalo+pgeNY/Ns98OuH1zTJMYy4xu92du9p6Zlpq35mx60O+yuNsa3yz+O/oEjl4+4tT15VYxHAkXHMJtC0r6HffH7TB1pNTyFwcw9M10COtOe6RpPRFgENsVtwo5z7tNlvizDjMLdwQ43LTrgmha8rQXNHHqNY/dlUm01QoUmtN743xuW6ht5eNbDrn1fDsoavxzwH4kj1LSo3AKDmw2+bte7rdxtmN5tOn7t8SsqlAgi8rYCgBJaOHkSePFFYNUqMcTwRZjzmzJqWlbxFEqeD5tAQovCS6BU6fsAAMWK3uKzniYUzLQOX4YYxmt7jqv//P6u0D++BI7Z9+Brqs54rSx7lls9T03LU2gxMzrM6ICm3zR1E7ravQaKcmG2TqU90Bt83cBvPDyjj82eC3vQ55c++n04dE3L5rAh9vtY3DnJfP3PE+0FCJD780yz4e83xsxeL0OLDi/yqqdZ+u1P2I/lR5d7lQdD5ejKOWqv8dJdL/kt16bcrxc2hw1NKzV1GZp4UjS8KD5q/5HruHdD/6bzGr7+D4oVcbcgfbD2g27Ho+4zjx2pEAq90GrVCvjiC6B9+8B1AW/rQSsEElpWpg+1ef6K5R/1Wc/q9KCvNS1/U2zGB2QgTcuoHdkddiRlJnn1keXI8mlNaHPYvMzktSmplMyUoF4YNMyEltUYcalZqUjOSMal1EteBjdGE3CrU2AaxulYO9vdnJBtDpv/6UGwJSfsE1dP4HTiaew6vyuosWl80E6mwG8qfhOqRIfGj3RQ00F4p+07ruMnGz3p5ftXp2wdr3Ztq7f1Ovfp/7d35uFVVVf//6w7JTfzHEgCJMgUJplkEFFQRMQ6g4pax5+2BVFqbXGqqG/fDm9rUattpU51qFi11mItDlSwWlEQFAfmORBCCCEmuRnusH9/nHtv7pyBhJBkf54nT+7ZZ59z9r4nOevsvdf6rnOWhJUF0hKPO6fHSV5yHjV3R/bEqr+3nrum3IVarFCLFT8YF5wssn96f/8+H2qxivr/FOp4seLqJgEBx90O7jyt87ONn8h0mNESkadF5JCIfBWjzlTvYt7XIhLuRtTBfPIJ7G9d+If/7bglaRh8hL4Rt3ak9cCqB3jwgwcBQystGhWV/4l4fogxPRjFwSKUaOtRzU0P3rz8Zr9sUqxYrKDpQRU+PfjIJ48AkB6f3mp5q79v/ntEF+aiR4padHyds47xT44n5zc5Ye7VTrfTb5RbK/gbOE3mdAcH7bqVu1mX95bIXX3npe/Q9+G+zQbWRsP3gO2T0ifIgeBY6JfWzy9VBk2u9IEeqpFCLE7re1pY2cSCiRGv4Xu5PG9g8/JXw3OGx7xGKMm24NCAPil9ItYL/b76pRoyfZG8NM8sMt6afZ6cY3uPBWBI1pBm29PT6Mjg4meBx4CIWigikgb8HpiplNorIsd9cndi5L/3FtFcXqNAQt+YQx82zT2EA9ciAh9soWze8v9oKPl/1DrCp8raMj0YSHNrWoFGMbDu0583LRSGTg8G0tz0oC9Y+vR+p0cdgTjdzqApNx/v7ng3WrdahMPpYPPhzUB4oHiju9Gfa6q1BN6HqoaqoHvr8riaXdPqCLmrARkDgoK+fYa1b2pfbhl/C8u3LmflrpVRj19x1Qoa3A0opXhqw1Ms37rcv++K4Vdw75R7SbAmBPXNd89WXrOSi5ZdxOo9q0m3N8WRPX/x84zqNYrirGImFkzkaP1Rvxjw+PzxrLxmJVaTlTqXESgfZ45jdO/RfHHwC8b0HsOsgbOwmCxsrdhKojWRW1fcGhST9fisx/2fX5nzCr0f6g3Aq3NeZVSvUWF9HJk7khVXrSArIYuSb0uCjO3u23b7Df34/PFcOeJKv9v/u999l60VW5lWNC3snG9c8QZ7q/b6/97/fe2/Wb17NVP6TYkZU9gT6TCjpZT6QEQKY1S5EvibUmqvt347pFtsObFismLhe2BG8tSKRqhRWvbVMm78x43cfdrdjM0by6V/vbRVx0fjrVKYPwAOloW7ALckTivm9GDAA3LUE03/yJGEURtcDWw/st2vnu0/R4CxnvHCjCCvtcB2/Oa/v/HHXz214Sme2vAU+cnGWt4bW96IKp/1v//5Xx5Y/QA/OfUn7K/ezwuXvMDCFQv5/brfR+1XIHe8cwcfl3wcVh44Srvn3/cE7ftonxGjlWhNjPlCEYnAF5/H1z4etO+fW/8ZcyS1r2pfq6/XEuafMp8fvv1D/7bPsPZN7YvZZGZSwaSYRuucAU3rMyISZLQuGHQBw3KGBZ0XmkYuafFpXHPyNazes5peib38+81i9o+GfF5+PqNlEpN/lBLK2DxjtDI+fzzQNJJ79NNH/Ubr4iEXk2HP8B/TK6kXE/In8Mn+TxieM5yTMk4KO6+I+Pvpu4aPfmn9grbH9BrjN1oDMwcyMHNgxLYm2ZIYmt2kTZsSl8L5g8+PWLen05kyToMAq4isApKBR5RSsRUq25Gbonv2xsT3cG3NSCv04eNT0/75hz+PVD2Mlq7hvLoffved57HuvxNomsZyOIL1ytoy0grsQ3PZWRvcDSxetTgswDbQ8IWuJwW2w2ewAglcS3ro44ciXveB1Q8A8H//NYSnn7/4ef+0YkuIdt5YD2kfVrMV2lGAu7mpv9YarJzEHIZlDwvSxANjnWhH5Q6O1B3B4XQwPGc4Pz/z5zS6G5lQMMEv2Oyb6rp21LXsr97POSedw9H6o9y64lYa3Y3cddpdXDwkWHVi1sBZ3Dn5Tq4ddS1Pb3iaS4c2vZxdP+p69lTtQSnFTyb/xF9+zknncP2o67l90u0MyhzE8q3LuaQ4fB13yTlL2pzC5vmLn2fJx0sQEX406Udh+1+45AVe+vIlBmUOatP5A/nBKT/g5a9f5rpR17X5HC/PfjmmTFxPozONlgUYC5wF2IGPRWSNUmpraEURuRm4GcAWK5iqFWzcGHv/fffBgw+Gl/sernWuuqB5+Vi0Nho/lNZkLi3xDGGfezCBRmvNJwP5IEBWMHCE43s4VjgqYiqWNzcVFfgAqW2sjZg0MtZ6XGvcqFsajBmYeTcad70XPe6tNeQl57VI3641jOk9pt0SXZbdYUxr/n3z34MkjVZdtwqAvkv64nA6KEorYnr/6f79vnvmW7cZkDGApy9smvJd9N4iGt2N3D7pdrISsoKuaTFZ+MV0wxPu/87+v6B9g7MG89Kl4WuA+Sn5/vMPyxnGotMWRezPwomRBahbQq+kXvzq7OiiuwMyBvDTM9ou4xRIgjWBT286tqSXlw27rPlKPYjO9B4sAVYopWqVUoeBD4CI+bKVUkuVUuOUUuMslvaxs0dDni9zQoL6580zYrdCactIq6UKzu3BKX86hX/v+ndQWXJquNeVD19/mluob02Oq1CZHx/R5HaAVrljt9QJ5vZ3bm+2zi8/+mWLrxuLlLiUFr/EtJSitCJuGtOyKYFJBZO4bNhlnFl0JoVphcwbNy9s5AOGI4uPwGm1+6feDxjJJwPxXT/SOgzAr882FD30SEBzvOhMo/UGMEVELCKSgCGBv+l4XTxwTeuWW+CvIXkB7UGhFMo/JeaL1nc4HS2SK4rGeQPPC3qAdCT5A6KrxpdWGW7aviDdaDTnRq9Q7TKd0hI6Yi2nNYSmmQBjVJGblNui4wO9x6b3n+53l/b9TC2cChiu1EvPX4parILihCLxwiUv8PLsl1l5zUp23baLx897nL9dHh6kG3jtldc0TXveMPoG1GIVpuIwc8BM1GIVNQj2prE3RTxOo+koOtLl/SXgY2CwiJSIyI0i8n0R+T6AUmoTsALYCHwKPKmUiuoe3964vEsoxcVGnFYoPqP1/e9D2vm/IPWXqZTVlPmz9foEU9vKoMxBrRYGbSv5S6IHJN/w5kIWLRNExTYELfFUa60relfFl6ok8KVDkKCF9FicnNs0oRApoNWXIiTwJWBw1uCY50yNS42530egV55G0xXpSO/BuS2o82sMAcbjjtv7DPZEGUD4kj/+4Q+w5olX+PxgsOhnWwJcA0m2JYd5IIa6G3cU7373XTaWbeRH7xiL0G8fBJe7JOYxLZkebInReu2y15r1lmwtt0+8nd+uaT8Ntzsn38n5g88nyZbEyX8Mn7G2mW3suHUHKXEpvL39ba5+/WpMYuLZC5/lVx/9it99arwFjcwdyd2n3c2I3BHsPrqbOmcdcZY4pvefztr9a6moq/B7tgXyp/P/xPrS9UGeeJcUX8JHN3zEkbojFGcVs6NyB3XOOib1mURZTRmZCeFpPwB23bbLny8NOG6je42mo+ixSSAbvMsigUbroYfgR+HORH5VhtA4mraSYc+ImI5gUsGk42K0pvefTl5ynt9ofVEFeYnpQGSh0jhzXLMjrfWl61sk8zPjpBmtbm9zzBo4q12MlsVkweVxMbnvZE7tc2rUerWNtfRP7w9AQYqhEpESl0J+Sj7nDjjXb7QuHnIxlw83YuZCR2FT+kWXjeqT2idsbQkIalOgK3Ys/brCtMKg7Vg50zSarkCPNVo+Ao3W7bfDwYPwzDOR6wZmbA2UGmotafFpYRlsgaA34o4mVLT0QG10Ze14k4dGV/MBtLGcUzLsGSw5Z0mH9HFSn0lR99075V6GZA3h6tevDiqfN26eP37rxtE3UlZbxj1T7uHJ9U8yuc9kf70l5yyhV1Iv3tnxDgsnLuSFjS9w3qAmlYUp/aZw92l3s2DCAsB4IZg3bh4Ol4Mfn/rj9uxmuyAiPDLzEab0jW40NZoTGWnrg7ezSExMVLW1x74QbzYbBuvPf4Zrroldd8wTY9hwcAO/OOsX3LWyyUV69tDZvPpNdNX1aAzKHMSt42/lln/dElS+cMJCf+qKQEbkjODLQ1+2+jqBJNmS/K7zarFiZ+VOTno0PHAyEvEmqG9bMmU/c4fP5S+XGg4h8kDrHFjG5Y1j3YF1DM8ZHpRDyodarHhkzSMsfDvcDVotNtTQzQ+aw8p97ai9u/a4vjBoNJ2BiDiUUpFVgbsQPVIw98ABw2D96lfNG6xAAg0W0CaDBYZQauB0kU+UNFA9ujir2P+5b2pf0uPTm1XHjoXPYD3xHSO1enPpIQI5FoPly95qNoW7gw/NHhoxcDQUn2dapDb71AwiTXv5RFlNYsJislCUFqw1OHvobPqn9w9T3dZoNCcuPXJ68JNPjN9TpzaVldeW0+huJDU+td3n/QPf6sF4+E4rmhakCn3P6cHyQN/M/4ZnNjzDDf+4gayELI4sMhQkfAoPv53x26hxSNGcHQKvF2mNqjWOIPMGZvD7bc2rpM87ZR6f7P8kYtbV9TevJ84S1+zIy3dspCSVB390EGjy6PMRqhru/KnhOBN4rVfmvNJs+zUazYlFjxxpPfus8bufVybM5XGR85scCpYUkPyL5LC1qmOJx4pEJFFXH7mJTbE+Ppf4SE4bseKmQlWoI+FTkw5qVwSjEI1po55oUT2f/M/oXqPDrxfjewjE5wgTaaTlO0emPbL3XCR0TJFG03XpkUbLl+wx25v9IFSlO5pnoC9uJloqAjCmq3ySOdGIZRw2zd/E1lsMJSuf0Yo0feVzQb965NXsXbiXtTet9bcvOS6Zrbds5fezogvFRvL0C4wb++iGj/yfv573dVjdS4sv5c25b4aV97IbxvB/hsEL44Hd0/jL1Cn8YPSVqBBDGzr6WnPjGr+qxLJLl3HNydcE1QucYiy7o4wttzTlr5pWNI1/XfUvvp73Nftvj55vZuetOyn5YWz3fo1Gc+LS46YH6wPieX3ZiEMVFpyeyCkuGt2NDM0eGjMoeFj2sGZTaMeSvEm3p4cFgEaq7xt1FKUV+V2k+6f3Z2vFVtweNwMzB7LpcGyBkZzEHH9yRQj+HgLdqyPl9BGRIC86MNyrU+NSOVj3BZMKL8FcYygy9Fb/4eOPc7Fas+nbN7rW34SCCfRL62c4iWSc5F+DSo5LDvoeEqwJ5CTmBH3PFpOFmQNmxuwvQFF6y3JoaTSaE5MeZ7RKvfJ3Tzdpfga5soM3dUeEwVCds47UuFRcpugxWrHSewDcM+Ue5p8yv0Vt/f6473Og+kCQCraPeafM42DNQRZNbhIUfebCZ3h4zcP+xHiBHnFPnv9k2DlWX7ea+96/j1e+MdZ2QvM3rb1pLWtK1kRcj/Lx5tw3qair4MO9HzJ3+FzyU/L569d/5cyx91Bfv4fa2i/Yt28JVVWrcTrL2bGjaR1u9+4Hsdl6s2Lu3zjo+NbfzmVfLWN4znCKs4qpbazl/qn38/P//JwFExbw4sYXW2ScNBpN96THubx/9BGcNs3BjU88hilrO/nJ+byx5Q02HNzgr1P+4/IgxeqxS8eyvnQ9qXGpDMocRFVDFVsrjCm8eEt80Mhrcp/JfHjDh0EL/oGOGKEOAq2lNef5eN/HnPq0MWLas3BP1MyzWyu2MvixwaTHp/u1FUPPH+os0Zp+KOXmyJF3SEubRmnpn+jz1K0AvB+g45uYOJLc3CvJyrqYhITjo2Go0fQkuovLe48baR04AAxYwVN7F8HeyHVCM+P6HAHqXHXYzLYgRw27xR5ktEJHWj4V7PbiyhFX8mVZy2K2At3qY7l1F6YVYjPbeGjGQ9z7/r1cNjQ8FcLsobPZULrBH4TbGkTMZGaeC0BBwQLmjdvMv7b/ixEjHqOiYjlHj66mtnYjO3duZOfOO/3HFRX9jLy8+Vit4enJNRpNz6THGa2S/R4ofD9mnW8bvqV3cu+w8kZ3I1azNcgw2a12/+gEtRNkYAAAGnJJREFUCPM8vOPUO46xxcG8eEl4gsRopManYrfYqXPVRfRA9GEz22i419C1un50eCZiaF/38MfPa8rSm5k5CwClPFRV/ZfPP29Sati161527boXMFNY+FN69boOmy0fUytizDQaTfeix3kPvlb+M5jwWMw6Qx4PdzzwETrSOlB9IPhYr9NCaEK8zgpg9aW5iOTifiIhYiIt7TSmTlWcfno9J5/8PkOHvkJcXB/Aze7d97NmTSEffGDls88m8NVXl1JRsQLVijxfGo2m69PjXll3Ov8LxxCmYzVZY8ZI/fYcQ7h1yy1bqKxrGoHtWbinVRmI24tX5rzC7qO7u1RskskUR3r6VABycmZTV7cTp/MI+/c/yqFDL1Nd/SnV1Z9y+LAvX5SJXr2uJTt7Nqmpk7FYWpamQ6PRdD163EjL4Wq9E0dgcLHNbIvpIehLspdhzwhS4s5OzO4Ud+tEWyLDcoYd9+u2J3Z7f1JSxlFc/BxnnNHA+PFbKC5+gaysi8nMPB/wcPDgM3z55Xl8+GEa69efRmXl+zQ2Hu7spms0XQoRmSkiW0Rku4jcGWH/7SLyjYhsFJGVItIvYN+1IrLN+3Nth7WxO3gPOp1OSkpKqK9vPqni3iMHUCYnuUm5lNUYQcDp9nRMYqLCUeGv1ze1r99YlVaX+t3BE2wJNLgaoqbq6JfWL2L5iUp8fDwFBQVYrS1XwzjRcDi24XZXU1X1X7ZvXxC0LyPjPPr3/wWJicOQGK77Gk13pznvQRExA1uBs4ESYC0wVyn1TUCdacAnSimHiPwAmKqUulxEMoB1wDhAAZ8BY5VS0dNHtJFuMT1YUlJCcnIyhYWFzUouOfa5sJLIyD79WXdgHWCoiDe4GoKU1E/KOQmH00G6PR1VrvxpNzLsGdQ01oTFNPkoziuOWH4iopSioqKCkpISioq6btBtQsJAAJKTx1BQcAslJb+jrOx5qqvXcuTIPzly5J+AkJf3AzIzZ5GRMQulXJhaIVul0fQAxgPblVI7AURkGXAh4DdaSqlAL7Y1gC/nzznAu0qpI95j3wVmAi+1dyO7hdGqr69vkcECwyXd58IemKI89NhtR7ZR76rnZFtw5lpByEvOY/fR3ZjERLItmaqGqnboxfFHRMjMzKS8vLyzm9KuFBQsoKBgATU1X1JTs57t2xcSH19IWdlzHDjwe8zmZNxuQ7qrd+/vkZ19CWlp07QR03R3LCKyLmB7qVJqacB2PrAvYLsEmBDjfDcC/4pxbP4xtDUq3cJoQStEbUUh3qW8gZkD/cU+zTsfvtgrl8flN3I+shKy/N6BDqeDqvKuabSg/cWATySSkkaQlDSCXr2M6XWPx0lZ2XMcPbqasrLnASgtfYLSUkP8Nzl5HElJY8nP/wFxcf2wWFL0lKKmO+FSSo2LsT/SwyDi+pGIXI0xFeiTCGjxscdKtzFaLceDKcKDOppU0dfl4WKxgVjEQnVVNSteX8Gc6+a0ujWzZs3iL3/5C2lpOoC2ozGZrPTufSO9e99IcfFzuFxVVFauxOHYQn39Tioq3qK6ep3fiAH07XsnVms2CQlDyczU8lGabk0JEKgGXgAcCK0kItOBe4AzlFINAcdODTl2VUc0skcZLaUwRloRjFZbRxw2i41ell68+tyrEY2W2+3GbA5PgOjjrbfeatN1NceOxZJKdnZwEsr6+j1UVX3Izp130tBQwt69v/Tvi4srIDl5AunpZ5KePh27/SREot9bjaaLsRYYKCJFwH7gCuDKwAoiMhp4ApiplDoUsOtt4Oci4lP7ngFEV8c+BnrU3IfHA+DB1M7dfuCnD7B/z36uPPtKfvzjH7Nq1SqmTZvGlVdeyYgRIwC46KKLGDt2LMOGDWPp0qZp5MLCQg4fPszu3bspLi7mpptuYtiwYcyYMYO6urqway1fvpwJEyYwevRopk+fTlmZ4QFZU1PD9ddfz4gRIxg5ciSvvfYaACtWrGDMmDGcfPLJnHXWWe3a7+5IfHw/cnOvYtKkfZxxhodTTz3EqFEfkJ09BxEbR4++z7Zt8/n008GsXm3hww+z+OKLmZSU/I7y8tdxOivwRElto9GcyCilXMAtGAZoE/BXpdTXIvKgiFzgrfZrIAl4RUQ+F5F/eI89AvwPhuFbCzzoc8pob7qFy/umTZsoLja89hYuhM8/j3ysUooaZw0WbNht4QoR1Y3VEY6CQUMd/OhBY40x054ZFm+1e/duzp11Lp9u+JTkuGRWrVrFeeedx1dffeX3yjty5AgZGRnU1dVxyimnsHr1ajIzMyksLGTdunXU1NQwYMAA1q1bx6hRo7jsssu44IILuPrqq4OuVVlZSVpaGiLCk08+yaZNm3jooYdYtGgRDQ0NPPzww/56LpeLMWPG8MEHH1BUVORvQyiB358mNkp5OHToZWpqNqCUG6ezgurqT3A4NvvriFjJzb2GjIwZ1NfvJSvrfOz2gXp9TNOpaMHcLkhH2mezyezP+wQwfvz4IDfyRx99lNdffx2Affv2sW3bNjIzg7PtFhUVMWrUKADGjh3L7t27w65TUlLC5ZdfTmlpKY2Njf5rvPfeeyxbtsxfLz09neXLl3P66af760QyWJrWIWIiN3cuublz/WVKeSgtfYqams9paNhLRcWbHDz4FAcPPgXAzp0/BiAhYQgDBhgvFSkpE6mv30tS0ojj3wmNpgvT7YyWd6ARkdo6N5sqt5Bh6UP/nNyw/ZvKS8ISQraVxMSmF5pVq1bx3nvv8fHHH5OQkMDUqVMjBkLHxTWN/sxmc8TpwQULFnD77bdzwQUXsGrVKu6//37AGEWGrstFKtO0PyIm8vJuCiprbCzn8OHX2b79NhITR+B0VuBwbGbjxmBnDqs1C6Xc9Ot3HyZTHLm5V2OxJKPRaCLT7YxWLFxuQ8UikvcgQHG2MUW2rWJbq2KvkpOTqa6OPLUIUFVVRXp6OgkJCWzevJk1a9a0otXh58rPN8If/vznP/vLZ8yYwWOPPRY0PThp0iTmz5/Prl27Yk4Patofmy2bvLybycu7GTBGY/X1e/n224+oqfmSurotHD36H5xOQ2pqx44fArBt2zzs9gEkJ49HxExBwULs9oF4PA5stvAXLY2mp9GjjNYBxx4gPCbrWMnMzGTy5MkMHz6cc889l/POC05DP3PmTP74xz8ycuRIBg8ezMSJE9t8rfvvv585c+aQn5/PxIkT2bVrFwD33nsv8+fPZ/jw4ZjNZhYvXswll1zC0qVLueSSS/B4POTk5PDuu+8eU181bUPEhN1eiN1eSG6A7XG76ykpMV409u9/lMbGUurqtlNXtx3AH08GJtLTzyQxcST19bvIyrqYjIxzsdmy0Gh6Et3OESMWXx3cRL27joHJo0hNib4oHmukFckRo6ujHTFOPNzuOmpq1nPkyNtUVLyFiAmlnNTUBHsZWSyZmExxZGaeT0LCQJKSxmK3n0RcXL52/NAEoR0xuiBu5YL6VMypsf+ZI6m4J9mSOiW1iKZnYjbbSU2dTGrqZIqKHvSXu1zfUlHxFuCmtvYrKitXUl29NigguukcqWRlnU9CQjEeTx1paWeRnDwOszlBGzRNl6VHGS2PcoPHgqkN/6+Z9kxttDSdjsWSQm7uFUFlxmyJB4djKxUVywHFwYPP4XB8Q1nZC/56e/b8DACbrTc2Wy4pKZOIi+uLUk6ys+dgs+ViMsVjNndOwlKNpiX0GKOllMKNCzzmNhkt7YWnOVEx/jbNJCYWk5hoTPP27bsIpRRO52EaGvZz4MDj2Gz5lJYuxWSKp6bm86Cpxt277/OdjcTE4bhcVeTkXE5OzlySkk7G6azAZss+/p3TaELoMUbLn21YNW+0chJz+Lbh26CyZJvhhuwTytVoTnREBJstG5stm8GD/wRAUdH9/v2VlSs5fHg5LlcldXXb8HgaEDFRXW0Ige/b92v27fu1t7YJ8JCTcxWJicOord1Ibu7VpKVNxWRK0C91muNGjzFa/nUqZWrWaPmyDwcSZ4ljXF4sgWSNpmuRnn4W6enh0l5KKSor38XlOorDsZmjR1fR0HCAurotHDr0or/eoUNNwewmUyIeTz3Z2RdjMtlJTz+btLSpxMf3CTu/RnMs9Byj5feSFGLo12o0PR4RISNjRkDJfSjl4ejRD0hLm0Jt7SaOHn0fp/MwtbVf4nSWU1e3i8bG/ZSXvwo0uerHxfXDZsumsdHI2danzx2AB4slnZycyzGZbMe5d5quTo8xWr7pQZMILZnJGJk7ko1lGzusPUlJSdTUaMcOTddAxER6+lQAkpKGk5Q0PGi/x+PC46mlpmYj9fU7sdnycDg2UVX1EZWV7+ByHQVg+/YF/mM2b74GAJutl1fWajcmUyIFBbeRlHQydvtAwAOY9PSjxk+PMVq+6UFTC70wbGb9BqjRtBSTyYLJlEpa2hRgCgAZGWdTUHArYCTgrKvbQWNjKdu2zQsSGG5sPEhFxb/wpWb65puPgs5tsaSTlnYGFksmNlsuiYkjsFozsNsHYrd3r5hJTfP0HKPlnR40d8Ab26JFi+jXrx/z5s0DDNWK5ORkvve973HhhRdSWVmJ0+nkZz/7GRdeeGHMc1100UXs27eP+vp6brvtNm6+2ZABWrFiBXfffTdut5usrCxWrlxJTU0NCxYsYN26dYgIixcv5tJLL233/mk0x4rJZCUxcQiJiUMYP35T2H6lFG53LQ7HJhoa9lJdvYG9e/+X7OzL8HgacDg2Bxk6H2ZzEm53LfHx/TGZrFituaSmnkZCwmDi4/uRmDgSiyVZ5z3rRnSYIoaIPA18BziklBoeo94pwBrgcqXUq82dt9nUJCsW8vnB8NwkbuXG4XRgcttJtLfMVvtSlQzKHMRLl74Utd6GDRtYuHAhq1evBmDo0KGsWLGCvLw8HA4HKSkpHD58mIkTJ7Jt2zZEJOr0YKQUJh6PJ2KKkUjpSNLT08PO2RxaEUPTFXC766iv34XLVUl9/T7q6rZSV7eT+vrdeDy1fq/HUESsiNj8hkzEis3Wm/T06SQmDsXjacBu74/JFJ6uqDuhFTGa51ngMeC5aBXEeP35FUbSseNCawZaceY4GtwNJFpj3+fRo0dz6NAhDhw4QHl5Oenp6fTt2xen08ndd9/NBx98gMlkYv/+/ZSVldGrV6+o54qUwqS8vDxiipFI6Ug0mu6K2WwnMXEoAKmp4fudzgoOH15OUtIoKivfxWJJpaFhH3V12zl8+A1qatZTU7PeX3///kf8ny2WdMzmFDweB1lZF+FwbMbl+pb09LPIzr4Um603cXF53d6wdQU6zGgppT4QkcJmqi0AXgNOaa/rPjwzcm6S6oZqtlRsIdU1iIF9U9rrcn5mz57Nq6++ysGDB7niCkOx4MUXX6S8vJzPPvsMq9VKYWFhxJQkPqKlMImWYkSnHtFomrBaM+nd+zoAkpNHBe1Tyo1SHpRy4XBsprz8Vaqq/oPZnILLVeENxC7H6SyntPRP/uNqa7+gpOS3/m2TKZGkpJGAIGLBYkkjMXEoaWlTATM2Ww4JCUMxmXrMystxp9O+WRHJBy4GzqQZoyUiNwM3A9hsbXOQ8HkPmtsih9ECrrjiCm666SYOHz7snyasqqoiJycHq9XK+++/z549e2KeI1oKk2gpRiKlI9GjLY0mHBGzd13LSnLyaJKTR4fVUUrhclVhNtspLX0KszkRqzWX6upPcbmOopQHh+NrKitXQoA+aUXFP9i795dB54qL64fFkkJ8fBEWSxpWayYpKaditw/AbE7CajVECvR6W+vpzNeBh4FFSil3c6MFpdRSYCkYa1ptuVij0zjMZu2YkcmwYcOorq4mPz+f3r17A3DVVVdx/vnnM27cOEaNGsWQIUNiniNaCpPs7OyIKUaipSPRaDStR0SwWg1hgfz8ef7yzMzgxJ2G00g1FksKLte3uFzfcujQMu8obSnZ2XNwu6txOLZQW7uR+vrd3iOXRLimjbi4fBIShmCxpGG3D0IpF3Z7f5KTx9PYeIC0tDNQyqM1Ib10aGoS7/Tgm5EcMURkF+CzIFmAA7hZKfX3WOdsa2qSfeWVlDl3MDB1KKmJCS3uQ09AO2JoNB2HUh4aG0uprf2GmprPsVhSqKr6L0o1Ule3Hbe7Bo+nkfr6nVHPIWIhPr6Q3r1vom/fn7SpHdoR4xhRSvkDLETkWQzjFtNgHQvpqVbqq9Oxx+u5Zo1Gc/wQMREXl09cXD4ZGWcDkJf3vbB6TmclIlbq6rbR2FhKff1eqqvXEheXR03NRszmBOLj+x3v5p9wdNgTXEReAqYCWSJSAiwGrABKqT921HWjkWRLYmBm0vG+rEaj0bQIq9VYjzbW23xrbt/vtPacqHSk9+DcVtS9rqPaodFoNJruQ7dJX9qRa3PdGf29aTSarkS3MFrx8fFUVFToB3ArUUpRUVFBfHx8ZzdFo9FoWkS38EooKCigpKSE8vLyzm5KlyM+Pp6CgoLOboZGo9G0iA51ee8IIrm8azQajSY2LXF5F5GZwCOAGXhSKfXLkP2nY8TYjgSuCNSLFRE38KV3c69S6oL2bL+PbjHS0mg0Gs2x4dWCfRw4GygB1orIP5RS3wRU2wtcB9wR4RR1SqlREcrbFW20NBqNRgMwHtiulNoJICLLgAsBv9FSSu327vN0RgOhmzhiaDQajaZZLCKyLuDn5pD9+cC+gO0Sb1lLifeed42IXHTMrY1ClxtpORwOJSJ1bTzcArjasz1dAN3nnoHuc8/gWPpsV0qNi7E/kjBra5we+iqlDohIf+DfIvKlUmpH65rYPF3OaCml2jw6FJF1zdy0bofuc89A97ln0MF9LgH6BGwXAAdaerBS6oD3904RWYUh69HuRktPD2o0Go0GYC0wUESKRMQGXAH8oyUHiki6iMR5P2cBkwlYC2tPtNHSaDQaDUopF3ALRib5TcBflVJfi8iDInIBgIic4tWSnQM8ISJfew8vBtaJyBfA+8AvQ7wO240uNz14jCzt7AZ0ArrPPQPd555Bh/ZZKfUW8FZI2X0Bn9diTBuGHvdfYERHts1Hlwsu1mg0Gk3PRU8PajQajabL0GOMlojMFJEtIrJdRO7s7Pa0FyLSR0TeF5FNIvK1iNzmLc8QkXdFZJv3d7q3XETkUe/3sFFExnRuD9qGiJhFZIOIvOndLhKRT7z9fdm7kIyIxHm3t3v3F3Zmu48FEUkTkVdFZLP3fk/qzvdZRH7o/Zv+SkReEpH47nifReRpETkkIl8FlLX6vorItd7620Tk2s7oy/GgRxitAHmSc4GhwFwRGdq5rWo3XMCPlFLFwERgvrdvdwIrlVIDgZXebTC+g4Hen5uBPxz/JrcLt2EsFvv4FbDE299K4EZv+Y1ApVJqALDEW6+r8giwQik1BDgZo//d8j6LSD5wKzBOKTUcQwvvCrrnfX4WmBlS1qr7KiIZGIl2J2AoWyz2Gbpuh1Kq2/8Ak4C3A7bvAu7q7HZ1UF/fwNAO2wL09pb1BrZ4Pz8BzA2o76/XVX4wFoJXAmcCb2IERR4GLKH3G8MTapL3s8VbTzq7D23ocwqwK7Tt3fU+06TOkOG9b28C53TX+wwUAl+19b4Cc4EnAsqD6nWnnx4x0uLY5Um6BN4pkdHAJ0CuUqoUwPs7x1utO3wXDwM/AXz6Z5nAUWW47EJwn/z99e6v8tbvavQHyoFnvNOiT4pIIt30Piul9gO/wRBoLcW4b5/R/e+zj9be1y59v1tDTzFaxypPcsIjIknAa8BCpdS3sapGKOsy34WIfAc4pJT6LLA4QlXVgn1dCQswBviDUmo0UEvTlFEkunS/vVNbFwJFQB6QiDE1Fkp3u8/NEa2fPaX/PcZoHZM8yYmOiFgxDNaLSqm/eYvLRKS3d39v4JC3vKt/F5OBC0RkN7AMY4rwYSBNRHxxh4F98vfXuz8VOHI8G9xOlAAlSqlPvNuvYhix7nqfpwO7lFLlSikn8DfgVLr/ffbR2vva1e93i+kpRqvN8iQnOiIiwFPAJqXUbwN2/QPweRBdi7HW5Su/xuuFNBGo8k1DdAWUUncppQqUUoUY9/HfSqmrMKLwZ3urhfbX9z3M9tbvcm+gSqmDwD4RGewtOgtDJqdb3meMacGJIpLg/Rv39bdb3+cAWntf3wZmiCGnlA7M8JZ1Pzp7Ue14/QCzgK0YAo73dHZ72rFfp2FMA2wEPvf+zMKYz18JbPP+zvDWFwxPyh0YWUbHdXYfjqHvU4E3vZ/7A58C24FXgDhvebx3e7t3f//Obvcx9HcUsM57r/8OpHfn+ww8AGwGvgKeB+K6430GXsJYt3NijJhubMt9BW7w9n87cH1n96ujfrQihkaj0Wi6DD1lelCj0Wg03QBttDQajUbTZdBGS6PRaDRdBm20NBqNRtNl0EZLo9FoNF0GbbQ0muOIiEz1KdNrNJrWo42WRqPRaLoM2mhpNBEQkatF5FMR+VxEnvDm76oRkYdEZL2IrBSRbG/dUSKyxpvf6PWA3EcDROQ9EfnCe8xJ3tMnBeTFetGr+KDRaFqANloaTQgiUgxcDkxWSo0C3MBVGKKt65VSY4DVGPmLAJ4DFimlRmKoFPjKXwQeV0qdjKGb55NRGg0sxMjt1h9DT1Gj0bQAS/NVNJoex1nAWGCtdxBkxxAs9QAve+u8APxNRFKBNKXUam/5n4FXRCQZyFdKvQ6glKoH8J7vU6VUiXf7c4xcSh92fLc0mq6PNloaTTgC/FkpdVdQochPQ+rF0kCLNeXXEPDZjf4/1GhajJ4e1GjCWQnMFpEcMFKZi0g/jP8Xn8L4lcCHSqkqoFJEpnjLvwusVkZOsxIRuch7jjgRSTiuvdBouiH6DU+jCUEp9Y2I3Au8IyImDPXt+RiJF4eJyGcYmXEv9x5yLfBHr1HaCVzvLf8u8ISIPOg9x5zj2A2NpluiVd41mhYiIjVKqaTObodG05PR04MajUaj6TLokZZGo9Fougx6pKXRaDSaLoM2WhqNRqPpMmijpdFoNJougzZaGo1Go+kyaKOl0Wg0mi6DNloajUaj6TL8fwRx5zUjm2X/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
    "\n",
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
